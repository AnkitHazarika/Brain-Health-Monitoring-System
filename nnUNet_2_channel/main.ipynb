{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Set correct nnU-Net paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet paths set:\n",
      "RAW: D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_raw\n",
      "PREPROCESSED: D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_preprocessed\n",
      "RESULTS: D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE = r\"D:/Capstone/Experiment 3/nnUNet_2_channel\"\n",
    "\n",
    "os.environ[\"nnUNet_raw\"] = BASE + r\"/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = BASE + r\"/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = BASE + r\"/nnUNet_results\"\n",
    "\n",
    "print(\"nnUNet paths set:\")\n",
    "print(\"RAW:\", os.environ[\"nnUNet_raw\"])\n",
    "print(\"PREPROCESSED:\", os.environ[\"nnUNet_preprocessed\"])\n",
    "print(\"RESULTS:\", os.environ[\"nnUNet_results\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create base folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base folders ensured\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.environ[\"nnUNet_raw\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"nnUNet_preprocessed\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"nnUNet_results\"], exist_ok=True)\n",
    "\n",
    "print(\"✅ Base folders ensured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Verify dataset folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Dataset124_ISLES22_2CH NOT FOUND in nnUNet_raw\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.environ[\"nnUNet_raw\"], \"Dataset124_ISLES22_2CH\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"❌ Dataset124_ISLES22_2CH NOT FOUND in nnUNet_raw\")\n",
    "else:\n",
    "    print(\"✅ Dataset found:\", dataset_path)\n",
    "    print(\"Contents:\", os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: DATASET Conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects found: 250\n",
      "\n",
      "✅ Converted cases: 250\n",
      "❌ Failed cases:    0\n",
      "\n",
      "✅ dataset.json written for 2-channel (DWI + ADC)\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, glob\n",
    "import SimpleITK as sitk\n",
    "from pathlib import Path\n",
    "\n",
    "BIDS_ROOT = r\"D:\\Capstone\\Experiment 3\\Datasets\\ISLES-2022\"\n",
    "OUT_ROOT  = r\"D:\\Capstone\\Experiment 3\\nnUNet_2_channel\\nnUNet_raw\\Dataset124_ISLES22_2CH\"\n",
    "\n",
    "IMAGES_TR = Path(OUT_ROOT, \"imagesTr\")\n",
    "LABELS_TR = Path(OUT_ROOT, \"labelsTr\")\n",
    "for p in (IMAGES_TR, LABELS_TR): \n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def resample_to_ref(img, ref, is_label=False):\n",
    "    \"\"\"Resample img to reference image space/shape using SITK.\"\"\"\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ref)\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor if is_label else sitk.sitkBSpline)\n",
    "    resampler.SetTransform(sitk.Transform())  # identity\n",
    "    resampler.SetDefaultPixelValue(0)\n",
    "    return resampler.Execute(img)\n",
    "\n",
    "\n",
    "# Find all subjects\n",
    "subs = sorted(glob.glob(str(Path(BIDS_ROOT, \"sub-strokecase*\"))))\n",
    "print(\"Subjects found:\", len(subs))\n",
    "\n",
    "ok, failed = 0, []\n",
    "\n",
    "for sub_path in subs:\n",
    "    sub = Path(sub_path).name\n",
    "    case_id = re.findall(r\"\\d+\", sub)\n",
    "    if not case_id:\n",
    "        failed.append((sub, \"could_not_parse_id\"))\n",
    "        continue\n",
    "\n",
    "    case_num = case_id[0]\n",
    "\n",
    "    ses = Path(sub_path, \"ses-0001\")\n",
    "    dwi  = Path(ses, \"dwi\",  f\"{sub}_ses-0001_dwi.nii.gz\")\n",
    "    adc  = Path(ses, \"dwi\",  f\"{sub}_ses-0001_adc.nii.gz\")\n",
    "    label = Path(BIDS_ROOT, \"derivatives\", sub, \"ses-0001\", f\"{sub}_ses-0001_msk.nii.gz\")\n",
    "\n",
    "    for needed in [dwi, adc, label]:\n",
    "        if not needed.exists():\n",
    "            failed.append((sub, f\"missing: {needed.name}\"))\n",
    "            break\n",
    "    else:\n",
    "        try:\n",
    "            dwi_img = sitk.ReadImage(str(dwi))\n",
    "            adc_img = sitk.ReadImage(str(adc))\n",
    "            lab_img = sitk.ReadImage(str(label))\n",
    "\n",
    "            adc_r = resample_to_ref(adc_img, dwi_img, is_label=False)\n",
    "            lab_r = resample_to_ref(lab_img, dwi_img, is_label=True)\n",
    "\n",
    "            sz = dwi_img.GetSize()\n",
    "            if adc_r.GetSize()!=sz or lab_r.GetSize()!=sz:\n",
    "                failed.append((sub, f\"resample_size_mismatch {sz} vs {adc_r.GetSize()}/{lab_r.GetSize()}\"))\n",
    "                continue\n",
    "\n",
    "            base = f\"ISLES22_{case_num}\"\n",
    "\n",
    "            sitk.WriteImage(dwi_img, str(IMAGES_TR / f\"{base}_0000.nii.gz\"), True)  # 0000 = DWI\n",
    "            sitk.WriteImage(adc_r,   str(IMAGES_TR / f\"{base}_0001.nii.gz\"), True)  # 0001 = ADC\n",
    "            sitk.WriteImage(lab_r,   str(LABELS_TR / f\"{base}.nii.gz\"), True)\n",
    "\n",
    "            ok += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            failed.append((sub, f\"error: {e!s}\"))\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Converted cases: {ok}\")\n",
    "print(f\"❌ Failed cases:    {len(failed)}\")\n",
    "for item in failed[:10]:\n",
    "    print(\"   \", item)\n",
    "\n",
    "\n",
    "# dataset.json for 2-channel adc + dwi\n",
    "ds_json = {\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"DWI\",\n",
    "        \"1\": \"ADC\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"stroke\": 1\n",
    "    },\n",
    "    \"numTraining\": ok,\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "\n",
    "with open(Path(OUT_ROOT, \"dataset.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ds_json, f, indent=2)\n",
    "\n",
    "print(\"\\n✅ dataset.json written for 2-channel (DWI + ADC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases detected: 250\n",
      "\n",
      "✅ GOOD cases: 250\n",
      "❌ Corrupted files: 0\n",
      "❌ Shape mismatches: 0\n",
      "❌ Missing modality cases: 0\n",
      "\n",
      "Corrupted file list:\n",
      "\n",
      "Shape mismatch cases:\n",
      "\n",
      "Missing modality cases:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "dataset_path = r\"D:\\Capstone\\Experiment 3\\nnUNet_raw\\Dataset123_ISLES22\\imagesTr\"\n",
    "\n",
    "bad_files = []\n",
    "bad_shapes = []\n",
    "missing_modalities = []\n",
    "all_good = []\n",
    "\n",
    "cases = {}\n",
    "\n",
    "# Group modalities for each case ID\n",
    "for f in os.listdir(dataset_path):\n",
    "    if not f.endswith(\".nii.gz\"): \n",
    "        continue\n",
    "    case_id = f.split(\"_\")[1]\n",
    "    modality_id = f.split(\"_\")[2].split(\".\")[0]\n",
    "    cases.setdefault(case_id, {})[modality_id] = os.path.join(dataset_path, f)\n",
    "\n",
    "print(\"Total cases detected:\", len(cases))\n",
    "\n",
    "\n",
    "for cid, mods in cases.items():\n",
    "\n",
    "    # Check if all 3 modalities exist\n",
    "    if len(mods) != 3:\n",
    "        missing_modalities.append((cid, list(mods.keys())))\n",
    "        continue\n",
    "    \n",
    "    shapes = []\n",
    "    corrupted = False\n",
    "\n",
    "    for mid, path in mods.items():\n",
    "        try:\n",
    "            img = nib.load(path)\n",
    "            shapes.append(img.shape)\n",
    "        except Exception as e:\n",
    "            bad_files.append((cid, mid, path, str(e)))\n",
    "            corrupted = True\n",
    "\n",
    "    if corrupted:\n",
    "        continue\n",
    "\n",
    "    # Check if all three shapes match\n",
    "    if not (shapes[0] == shapes[1] == shapes[2]):\n",
    "        bad_shapes.append((cid, shapes))\n",
    "    else:\n",
    "        all_good.append(cid)\n",
    "\n",
    "print(\"\\n✅ GOOD cases:\", len(all_good))\n",
    "print(\"❌ Corrupted files:\", len(bad_files))\n",
    "print(\"❌ Shape mismatches:\", len(bad_shapes))\n",
    "print(\"❌ Missing modality cases:\", len(missing_modalities))\n",
    "\n",
    "print(\"\\nCorrupted file list:\")\n",
    "for b in bad_files:\n",
    "    print(b)\n",
    "\n",
    "print(\"\\nShape mismatch cases:\")\n",
    "for b in bad_shapes:\n",
    "    print(b)\n",
    "\n",
    "print(\"\\nMissing modality cases:\")\n",
    "for b in missing_modalities:\n",
    "    print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW = D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_raw\n",
      "PRE = D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_preprocessed\n",
      "RES = D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"RAW =\", os.environ.get(\"nnUNet_raw\"))\n",
    "print(\"PRE =\", os.environ.get(\"nnUNet_preprocessed\"))\n",
    "print(\"RES =\", os.environ.get(\"nnUNet_results\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ nnU-Net v2 loaded successfully\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import nnunetv2; print('✅ nnU-Net v2 loaded successfully')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset124_ISLES22_2CH\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 72. 112. 112.], 3d_lowres: [72, 112, 112]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 266, 'patch_size': (112, 112), 'median_image_size_in_voxels': array([112., 112.]), 'spacing': array([2., 2.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': (32, 64, 128, 256, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': (80, 112, 112), 'median_image_size_in_voxels': array([ 72., 112., 112.]), 'spacing': array([2., 2., 2.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': (32, 64, 128, 256, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_preprocessed\\Dataset124_ISLES22_2CH\\nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset124_ISLES22_2CH\n",
      "Configuration: 2d...\n",
      "Configuration: 3d_fullres...\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset124_ISLES22_2CH. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  0%|          | 1/250 [00:09<39:52,  9.61s/it]\n",
      "  2%|▏         | 5/250 [00:09<05:56,  1.45s/it]\n",
      "  3%|▎         | 8/250 [00:09<03:08,  1.28it/s]\n",
      "  4%|▍         | 11/250 [00:09<01:54,  2.09it/s]\n",
      "  6%|▌         | 14/250 [00:10<01:14,  3.15it/s]\n",
      "  7%|▋         | 18/250 [00:10<00:46,  5.02it/s]\n",
      "  8%|▊         | 21/250 [00:10<00:34,  6.70it/s]\n",
      " 10%|▉         | 24/250 [00:10<00:25,  8.70it/s]\n",
      " 11%|█         | 27/250 [00:10<00:20, 10.98it/s]\n",
      " 12%|█▏        | 30/250 [00:10<00:16, 13.36it/s]\n",
      " 14%|█▍        | 35/250 [00:10<00:11, 19.06it/s]\n",
      " 16%|█▌        | 39/250 [00:10<00:09, 22.60it/s]\n",
      " 17%|█▋        | 43/250 [00:10<00:08, 25.68it/s]\n",
      " 19%|█▉        | 47/250 [00:11<00:08, 22.87it/s]\n",
      " 21%|██        | 52/250 [00:11<00:07, 27.80it/s]\n",
      " 22%|██▏       | 56/250 [00:11<00:06, 30.01it/s]\n",
      " 24%|██▍       | 60/250 [00:11<00:05, 31.76it/s]\n",
      " 26%|██▌       | 64/250 [00:11<00:05, 33.09it/s]\n",
      " 27%|██▋       | 68/250 [00:11<00:05, 34.01it/s]\n",
      " 29%|██▉       | 72/250 [00:11<00:06, 27.25it/s]\n",
      " 31%|███       | 77/250 [00:12<00:05, 31.71it/s]\n",
      " 32%|███▏      | 81/250 [00:12<00:05, 32.78it/s]\n",
      " 34%|███▍      | 85/250 [00:12<00:04, 33.79it/s]\n",
      " 36%|███▌      | 89/250 [00:12<00:04, 34.93it/s]\n",
      " 37%|███▋      | 93/250 [00:12<00:05, 27.64it/s]\n",
      " 39%|███▉      | 97/250 [00:12<00:05, 29.56it/s]\n",
      " 40%|████      | 101/250 [00:12<00:04, 31.84it/s]\n",
      " 42%|████▏     | 105/250 [00:12<00:04, 32.36it/s]\n",
      " 44%|████▎     | 109/250 [00:13<00:05, 26.08it/s]\n",
      " 45%|████▍     | 112/250 [00:13<00:05, 26.43it/s]\n",
      " 46%|████▌     | 115/250 [00:13<00:05, 26.23it/s]\n",
      " 47%|████▋     | 118/250 [00:13<00:04, 27.04it/s]\n",
      " 48%|████▊     | 121/250 [00:13<00:04, 27.06it/s]\n",
      " 50%|████▉     | 124/250 [00:13<00:04, 27.20it/s]\n",
      " 51%|█████     | 127/250 [00:13<00:04, 27.28it/s]\n",
      " 52%|█████▏    | 130/250 [00:13<00:04, 26.84it/s]\n",
      " 54%|█████▎    | 134/250 [00:14<00:03, 30.10it/s]\n",
      " 55%|█████▌    | 138/250 [00:14<00:03, 32.20it/s]\n",
      " 57%|█████▋    | 142/250 [00:14<00:03, 33.15it/s]\n",
      " 58%|█████▊    | 146/250 [00:14<00:03, 26.70it/s]\n",
      " 62%|██████▏   | 154/250 [00:14<00:02, 38.21it/s]\n",
      " 64%|██████▎   | 159/250 [00:14<00:02, 40.25it/s]\n",
      " 66%|██████▌   | 164/250 [00:14<00:02, 41.55it/s]\n",
      " 68%|██████▊   | 169/250 [00:14<00:01, 43.10it/s]\n",
      " 70%|██████▉   | 174/250 [00:15<00:02, 33.73it/s]\n",
      " 71%|███████   | 178/250 [00:15<00:02, 34.80it/s]\n",
      " 73%|███████▎  | 182/250 [00:15<00:01, 34.97it/s]\n",
      " 75%|███████▌  | 188/250 [00:15<00:01, 40.78it/s]\n",
      " 77%|███████▋  | 193/250 [00:15<00:01, 42.11it/s]\n",
      " 79%|███████▉  | 198/250 [00:15<00:01, 43.16it/s]\n",
      " 81%|████████  | 203/250 [00:15<00:01, 43.35it/s]\n",
      " 83%|████████▎ | 208/250 [00:15<00:01, 34.41it/s]\n",
      " 85%|████████▍ | 212/250 [00:16<00:01, 34.34it/s]\n",
      " 86%|████████▋ | 216/250 [00:16<00:00, 34.47it/s]\n",
      " 88%|████████▊ | 220/250 [00:16<00:00, 34.96it/s]\n",
      " 90%|████████▉ | 224/250 [00:16<00:00, 35.44it/s]\n",
      " 91%|█████████ | 228/250 [00:16<00:00, 35.52it/s]\n",
      " 93%|█████████▎| 232/250 [00:16<00:00, 35.98it/s]\n",
      " 94%|█████████▍| 236/250 [00:16<00:00, 36.42it/s]\n",
      " 96%|█████████▌| 240/250 [00:16<00:00, 36.62it/s]\n",
      " 98%|█████████▊| 244/250 [00:16<00:00, 36.36it/s]\n",
      " 99%|█████████▉| 248/250 [00:17<00:00, 36.69it/s]\n",
      "100%|██████████| 250/250 [00:17<00:00, 14.55it/s]\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  0%|          | 1/250 [00:11<47:10, 11.37s/it]\n",
      "  1%|          | 2/250 [00:11<19:36,  4.74s/it]\n",
      "  2%|▏         | 6/250 [00:11<04:30,  1.11s/it]\n",
      "  4%|▎         | 9/250 [00:11<02:34,  1.56it/s]\n",
      "  5%|▌         | 13/250 [00:11<01:24,  2.80it/s]\n",
      "  7%|▋         | 17/250 [00:12<00:55,  4.23it/s]\n",
      "  8%|▊         | 20/250 [00:12<00:40,  5.66it/s]\n",
      " 10%|█         | 25/250 [00:12<00:27,  8.24it/s]\n",
      " 11%|█         | 28/250 [00:12<00:21, 10.09it/s]\n",
      " 12%|█▏        | 31/250 [00:12<00:17, 12.22it/s]\n",
      " 14%|█▎        | 34/250 [00:12<00:17, 12.60it/s]\n",
      " 15%|█▌        | 38/250 [00:13<00:12, 16.32it/s]\n",
      " 16%|█▋        | 41/250 [00:13<00:11, 18.33it/s]\n",
      " 18%|█▊        | 44/250 [00:13<00:10, 20.20it/s]\n",
      " 19%|█▉        | 47/250 [00:13<00:09, 21.87it/s]\n",
      " 20%|██        | 50/250 [00:13<00:10, 18.57it/s]\n",
      " 21%|██        | 53/250 [00:13<00:09, 20.60it/s]\n",
      " 23%|██▎       | 57/250 [00:13<00:07, 24.27it/s]\n",
      " 24%|██▍       | 60/250 [00:13<00:07, 25.06it/s]\n",
      " 25%|██▌       | 63/250 [00:13<00:07, 25.78it/s]\n",
      " 26%|██▋       | 66/250 [00:14<00:07, 26.24it/s]\n",
      " 28%|██▊       | 69/250 [00:14<00:08, 20.76it/s]\n",
      " 29%|██▉       | 73/250 [00:14<00:07, 24.66it/s]\n",
      " 30%|███       | 76/250 [00:14<00:06, 25.43it/s]\n",
      " 32%|███▏      | 79/250 [00:14<00:06, 26.00it/s]\n",
      " 33%|███▎      | 82/250 [00:14<00:06, 26.36it/s]\n",
      " 34%|███▍      | 85/250 [00:14<00:07, 20.77it/s]\n",
      " 35%|███▌      | 88/250 [00:15<00:07, 22.43it/s]\n",
      " 36%|███▋      | 91/250 [00:15<00:06, 23.77it/s]\n",
      " 38%|███▊      | 94/250 [00:15<00:06, 24.66it/s]\n",
      " 39%|███▉      | 97/250 [00:15<00:05, 25.51it/s]\n",
      " 40%|████      | 100/250 [00:15<00:05, 26.01it/s]\n",
      " 41%|████      | 103/250 [00:15<00:08, 16.82it/s]\n",
      " 42%|████▏     | 106/250 [00:15<00:07, 18.95it/s]\n",
      " 44%|████▎     | 109/250 [00:16<00:08, 17.06it/s]\n",
      " 45%|████▍     | 112/250 [00:16<00:07, 19.21it/s]\n",
      " 46%|████▌     | 115/250 [00:16<00:07, 17.18it/s]\n",
      " 47%|████▋     | 117/250 [00:16<00:07, 17.36it/s]\n",
      " 48%|████▊     | 119/250 [00:16<00:07, 17.67it/s]\n",
      " 48%|████▊     | 121/250 [00:16<00:07, 17.85it/s]\n",
      " 49%|████▉     | 123/250 [00:16<00:07, 17.95it/s]\n",
      " 50%|█████     | 125/250 [00:17<00:06, 17.91it/s]\n",
      " 51%|█████     | 127/250 [00:17<00:06, 18.09it/s]\n",
      " 52%|█████▏    | 129/250 [00:17<00:06, 18.14it/s]\n",
      " 52%|█████▏    | 131/250 [00:17<00:06, 18.23it/s]\n",
      " 53%|█████▎    | 133/250 [00:17<00:06, 18.27it/s]\n",
      " 54%|█████▍    | 135/250 [00:17<00:06, 18.22it/s]\n",
      " 55%|█████▍    | 137/250 [00:17<00:08, 14.09it/s]\n",
      " 56%|█████▋    | 141/250 [00:17<00:05, 19.62it/s]\n",
      " 58%|█████▊    | 144/250 [00:18<00:06, 17.12it/s]\n",
      " 59%|█████▉    | 147/250 [00:18<00:05, 19.41it/s]\n",
      " 60%|██████    | 150/250 [00:18<00:06, 14.34it/s]\n",
      " 61%|██████    | 152/250 [00:18<00:07, 12.67it/s]\n",
      " 62%|██████▏   | 154/250 [00:18<00:06, 13.72it/s]\n",
      " 63%|██████▎   | 157/250 [00:19<00:05, 16.58it/s]\n",
      " 64%|██████▎   | 159/250 [00:19<00:05, 16.99it/s]\n",
      " 64%|██████▍   | 161/250 [00:19<00:07, 11.59it/s]\n",
      " 65%|██████▌   | 163/250 [00:19<00:06, 12.89it/s]\n",
      " 66%|██████▌   | 165/250 [00:19<00:06, 14.06it/s]\n",
      " 67%|██████▋   | 168/250 [00:19<00:04, 17.13it/s]\n",
      " 68%|██████▊   | 170/250 [00:19<00:04, 17.46it/s]\n",
      " 69%|██████▉   | 173/250 [00:20<00:03, 20.14it/s]\n",
      " 70%|███████   | 176/250 [00:20<00:03, 22.14it/s]\n",
      " 72%|███████▏  | 179/250 [00:20<00:03, 18.47it/s]\n",
      " 73%|███████▎  | 182/250 [00:20<00:04, 16.64it/s]\n",
      " 74%|███████▎  | 184/250 [00:20<00:04, 14.01it/s]\n",
      " 74%|███████▍  | 186/250 [00:20<00:04, 14.92it/s]\n",
      " 75%|███████▌  | 188/250 [00:21<00:04, 12.83it/s]\n",
      " 76%|███████▌  | 190/250 [00:21<00:04, 13.93it/s]\n",
      " 77%|███████▋  | 192/250 [00:21<00:04, 12.10it/s]\n",
      " 78%|███████▊  | 194/250 [00:21<00:04, 13.30it/s]\n",
      " 78%|███████▊  | 196/250 [00:21<00:04, 11.84it/s]\n",
      " 79%|███████▉  | 198/250 [00:21<00:04, 10.91it/s]\n",
      " 80%|████████  | 201/250 [00:22<00:03, 14.20it/s]\n",
      " 81%|████████  | 203/250 [00:22<00:03, 15.15it/s]\n",
      " 82%|████████▏ | 205/250 [00:22<00:04, 10.76it/s]\n",
      " 83%|████████▎ | 207/250 [00:22<00:03, 12.21it/s]\n",
      " 84%|████████▍ | 210/250 [00:22<00:03, 12.79it/s]\n",
      " 86%|████████▌ | 214/250 [00:22<00:02, 17.47it/s]\n",
      " 87%|████████▋ | 217/250 [00:23<00:02, 16.16it/s]\n",
      " 88%|████████▊ | 219/250 [00:23<00:01, 16.59it/s]\n",
      " 89%|████████▉ | 222/250 [00:23<00:01, 15.58it/s]\n",
      " 90%|████████▉ | 224/250 [00:23<00:01, 16.21it/s]\n",
      " 90%|█████████ | 226/250 [00:23<00:01, 13.54it/s]\n",
      " 91%|█████████ | 228/250 [00:23<00:01, 14.54it/s]\n",
      " 92%|█████████▏| 230/250 [00:24<00:01, 15.41it/s]\n",
      " 93%|█████████▎| 232/250 [00:24<00:01, 16.17it/s]\n",
      " 94%|█████████▎| 234/250 [00:24<00:00, 16.70it/s]\n",
      " 94%|█████████▍| 236/250 [00:24<00:01, 13.54it/s]\n",
      " 95%|█████████▌| 238/250 [00:24<00:00, 14.67it/s]\n",
      " 96%|█████████▌| 240/250 [00:24<00:00, 15.56it/s]\n",
      " 97%|█████████▋| 242/250 [00:24<00:00, 12.85it/s]\n",
      " 99%|█████████▉| 247/250 [00:25<00:00, 16.51it/s]\n",
      "100%|█████████▉| 249/250 [00:25<00:00, 11.88it/s]\n",
      "100%|██████████| 250/250 [00:25<00:00,  9.74it/s]\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  0%|          | 1/250 [00:09<39:28,  9.51s/it]\n",
      "  2%|▏         | 5/250 [00:09<06:04,  1.49s/it]\n",
      "  4%|▎         | 9/250 [00:10<02:52,  1.40it/s]\n",
      "  5%|▌         | 13/250 [00:10<01:40,  2.35it/s]\n",
      "  6%|▋         | 16/250 [00:10<01:10,  3.32it/s]\n",
      "  7%|▋         | 18/250 [00:10<01:02,  3.72it/s]\n",
      "  8%|▊         | 21/250 [00:11<00:46,  4.92it/s]\n",
      " 10%|▉         | 24/250 [00:11<00:33,  6.69it/s]\n",
      " 10%|█         | 26/250 [00:11<00:31,  7.16it/s]\n",
      " 12%|█▏        | 29/250 [00:11<00:28,  7.68it/s]\n",
      " 13%|█▎        | 33/250 [00:12<00:24,  9.03it/s]\n",
      " 14%|█▍        | 35/250 [00:12<00:21, 10.16it/s]\n",
      " 15%|█▍        | 37/250 [00:12<00:21,  9.91it/s]\n",
      " 16%|█▌        | 39/250 [00:12<00:18, 11.20it/s]\n",
      " 16%|█▋        | 41/250 [00:12<00:19, 10.59it/s]\n",
      " 17%|█▋        | 43/250 [00:12<00:17, 12.00it/s]\n",
      " 18%|█▊        | 45/250 [00:13<00:18, 10.97it/s]\n",
      " 19%|█▉        | 47/250 [00:13<00:16, 12.38it/s]\n",
      " 20%|█▉        | 49/250 [00:13<00:17, 11.26it/s]\n",
      " 21%|██        | 52/250 [00:13<00:13, 14.55it/s]\n",
      " 22%|██▏       | 54/250 [00:13<00:15, 12.61it/s]\n",
      " 22%|██▏       | 56/250 [00:13<00:14, 13.77it/s]\n",
      " 23%|██▎       | 58/250 [00:13<00:15, 12.05it/s]\n",
      " 24%|██▍       | 60/250 [00:14<00:20,  9.41it/s]\n",
      " 25%|██▌       | 63/250 [00:14<00:20,  9.32it/s]\n",
      " 26%|██▋       | 66/250 [00:14<00:19,  9.26it/s]\n",
      " 28%|██▊       | 69/250 [00:15<00:17, 10.38it/s]\n",
      " 28%|██▊       | 71/250 [00:15<00:15, 11.61it/s]\n",
      " 29%|██▉       | 73/250 [00:15<00:16, 10.82it/s]\n",
      " 30%|███       | 75/250 [00:15<00:14, 12.12it/s]\n",
      " 31%|███       | 77/250 [00:15<00:15, 11.12it/s]\n",
      " 32%|███▏      | 79/250 [00:15<00:13, 12.50it/s]\n",
      " 32%|███▏      | 81/250 [00:16<00:14, 11.29it/s]\n",
      " 33%|███▎      | 83/250 [00:16<00:13, 12.71it/s]\n",
      " 34%|███▍      | 85/250 [00:16<00:11, 13.98it/s]\n",
      " 35%|███▍      | 87/250 [00:16<00:13, 12.14it/s]\n",
      " 36%|███▌      | 89/250 [00:16<00:11, 13.54it/s]\n",
      " 36%|███▋      | 91/250 [00:16<00:10, 14.69it/s]\n",
      " 37%|███▋      | 93/250 [00:17<00:12, 12.49it/s]\n",
      " 38%|███▊      | 95/250 [00:17<00:11, 13.78it/s]\n",
      " 39%|███▉      | 97/250 [00:17<00:10, 14.82it/s]\n",
      " 40%|███▉      | 99/250 [00:17<00:12, 12.51it/s]\n",
      " 40%|████      | 101/250 [00:17<00:15,  9.52it/s]\n",
      " 41%|████      | 103/250 [00:18<00:18,  8.13it/s]\n",
      " 42%|████▏     | 104/250 [00:18<00:17,  8.29it/s]\n",
      " 42%|████▏     | 105/250 [00:18<00:20,  7.11it/s]\n",
      " 43%|████▎     | 107/250 [00:18<00:21,  6.70it/s]\n",
      " 44%|████▎     | 109/250 [00:19<00:19,  7.34it/s]\n",
      " 44%|████▍     | 110/250 [00:19<00:18,  7.66it/s]\n",
      " 44%|████▍     | 111/250 [00:19<00:20,  6.69it/s]\n",
      " 45%|████▌     | 113/250 [00:19<00:21,  6.42it/s]\n",
      " 46%|████▌     | 115/250 [00:20<00:21,  6.29it/s]\n",
      " 47%|████▋     | 117/250 [00:20<00:21,  6.22it/s]\n",
      " 48%|████▊     | 120/250 [00:20<00:14,  9.19it/s]\n",
      " 49%|████▉     | 122/250 [00:20<00:11, 10.70it/s]\n",
      " 50%|████▉     | 124/250 [00:20<00:12, 10.24it/s]\n",
      " 50%|█████     | 126/250 [00:20<00:10, 11.74it/s]\n",
      " 51%|█████     | 128/250 [00:20<00:09, 13.14it/s]\n",
      " 52%|█████▏    | 130/250 [00:21<00:10, 11.60it/s]\n",
      " 53%|█████▎    | 132/250 [00:21<00:09, 13.06it/s]\n",
      " 54%|█████▎    | 134/250 [00:21<00:10, 11.55it/s]\n",
      " 55%|█████▍    | 137/250 [00:21<00:09, 12.35it/s]\n",
      " 56%|█████▌    | 139/250 [00:21<00:08, 13.52it/s]\n",
      " 56%|█████▋    | 141/250 [00:22<00:09, 11.94it/s]\n",
      " 57%|█████▋    | 143/250 [00:22<00:11,  9.38it/s]\n",
      " 58%|█████▊    | 145/250 [00:22<00:09, 10.93it/s]\n",
      " 59%|█████▉    | 147/250 [00:22<00:08, 12.42it/s]\n",
      " 60%|█████▉    | 149/250 [00:22<00:08, 11.26it/s]\n",
      " 60%|██████    | 151/250 [00:22<00:07, 12.72it/s]\n",
      " 61%|██████    | 153/250 [00:23<00:11,  8.35it/s]\n",
      " 62%|██████▏   | 155/250 [00:23<00:14,  6.72it/s]\n",
      " 62%|██████▏   | 156/250 [00:23<00:13,  7.04it/s]\n",
      " 63%|██████▎   | 157/250 [00:24<00:12,  7.39it/s]\n",
      " 63%|██████▎   | 158/250 [00:24<00:14,  6.46it/s]\n",
      " 64%|██████▍   | 160/250 [00:24<00:12,  7.28it/s]\n",
      " 64%|██████▍   | 161/250 [00:25<00:20,  4.43it/s]\n",
      " 65%|██████▍   | 162/250 [00:25<00:22,  3.99it/s]\n",
      " 65%|██████▌   | 163/250 [00:25<00:20,  4.14it/s]\n",
      " 66%|██████▌   | 164/250 [00:25<00:20,  4.25it/s]\n",
      " 66%|██████▌   | 165/250 [00:25<00:17,  4.97it/s]\n",
      " 66%|██████▋   | 166/250 [00:26<00:14,  5.71it/s]\n",
      " 67%|██████▋   | 167/250 [00:26<00:15,  5.33it/s]\n",
      " 67%|██████▋   | 168/250 [00:26<00:13,  6.07it/s]\n",
      " 68%|██████▊   | 169/250 [00:26<00:14,  5.56it/s]\n",
      " 69%|██████▉   | 172/250 [00:26<00:07, 10.02it/s]\n",
      " 70%|██████▉   | 174/250 [00:26<00:06, 11.94it/s]\n",
      " 70%|███████   | 176/250 [00:27<00:08,  9.10it/s]\n",
      " 71%|███████   | 178/250 [00:27<00:09,  7.83it/s]\n",
      " 72%|███████▏  | 180/250 [00:27<00:08,  8.20it/s]\n",
      " 72%|███████▏  | 181/250 [00:27<00:09,  7.16it/s]\n",
      " 73%|███████▎  | 183/250 [00:28<00:14,  4.49it/s]\n",
      " 74%|███████▍  | 185/250 [00:28<00:12,  5.39it/s]\n",
      " 74%|███████▍  | 186/250 [00:29<00:13,  4.71it/s]\n",
      " 75%|███████▍  | 187/250 [00:29<00:14,  4.22it/s]\n",
      " 75%|███████▌  | 188/250 [00:29<00:12,  4.83it/s]\n",
      " 76%|███████▌  | 189/250 [00:29<00:12,  4.77it/s]\n",
      " 76%|███████▌  | 190/250 [00:30<00:12,  4.71it/s]\n",
      " 76%|███████▋  | 191/250 [00:30<00:16,  3.65it/s]\n",
      " 77%|███████▋  | 192/250 [00:30<00:18,  3.12it/s]\n",
      " 77%|███████▋  | 193/250 [00:31<00:14,  3.86it/s]\n",
      " 78%|███████▊  | 194/250 [00:31<00:12,  4.64it/s]\n",
      " 78%|███████▊  | 195/250 [00:31<00:15,  3.58it/s]\n",
      " 78%|███████▊  | 196/250 [00:31<00:14,  3.83it/s]\n",
      " 79%|███████▉  | 197/250 [00:32<00:18,  2.89it/s]\n",
      " 79%|███████▉  | 198/250 [00:32<00:14,  3.63it/s]\n",
      " 80%|███████▉  | 199/250 [00:32<00:11,  4.43it/s]\n",
      " 80%|████████  | 200/250 [00:32<00:11,  4.50it/s]\n",
      " 80%|████████  | 201/250 [00:32<00:09,  5.29it/s]\n",
      " 81%|████████  | 202/250 [00:32<00:07,  6.04it/s]\n",
      " 81%|████████  | 203/250 [00:33<00:07,  6.69it/s]\n",
      " 82%|████████▏ | 204/250 [00:33<00:09,  4.94it/s]\n",
      " 82%|████████▏ | 205/250 [00:33<00:12,  3.66it/s]\n",
      " 82%|████████▏ | 206/250 [00:33<00:09,  4.46it/s]\n",
      " 83%|████████▎ | 207/250 [00:34<00:08,  5.28it/s]\n",
      " 83%|████████▎ | 208/250 [00:34<00:09,  4.33it/s]\n",
      " 84%|████████▎ | 209/250 [00:34<00:10,  3.85it/s]\n",
      " 84%|████████▍ | 211/250 [00:34<00:06,  6.05it/s]\n",
      " 85%|████████▍ | 212/250 [00:34<00:05,  6.62it/s]\n",
      " 85%|████████▌ | 213/250 [00:35<00:05,  7.13it/s]\n",
      " 86%|████████▌ | 214/250 [00:35<00:05,  6.21it/s]\n",
      " 87%|████████▋ | 217/250 [00:35<00:04,  7.51it/s]\n",
      " 88%|████████▊ | 219/250 [00:35<00:03,  7.98it/s]\n",
      " 88%|████████▊ | 221/250 [00:36<00:03,  7.26it/s]\n",
      " 89%|████████▉ | 223/250 [00:36<00:03,  7.78it/s]\n",
      " 90%|████████▉ | 224/250 [00:36<00:03,  6.87it/s]\n",
      " 90%|█████████ | 226/250 [00:37<00:05,  4.39it/s]\n",
      " 91%|█████████ | 227/250 [00:37<00:05,  4.42it/s]\n",
      " 91%|█████████ | 228/250 [00:37<00:04,  4.99it/s]\n",
      " 92%|█████████▏| 229/250 [00:37<00:03,  5.59it/s]\n",
      " 92%|█████████▏| 230/250 [00:37<00:03,  6.20it/s]\n",
      " 92%|█████████▏| 231/250 [00:38<00:03,  5.66it/s]\n",
      " 93%|█████████▎| 233/250 [00:38<00:02,  6.77it/s]\n",
      " 94%|█████████▍| 235/250 [00:38<00:01,  7.51it/s]\n",
      " 94%|█████████▍| 236/250 [00:39<00:03,  4.50it/s]\n",
      " 95%|█████████▌| 238/250 [00:39<00:02,  4.99it/s]\n",
      " 96%|█████████▌| 240/250 [00:39<00:01,  5.94it/s]\n",
      " 96%|█████████▋| 241/250 [00:39<00:01,  5.00it/s]\n",
      " 97%|█████████▋| 243/250 [00:40<00:01,  5.35it/s]\n",
      " 98%|█████████▊| 245/250 [00:40<00:00,  7.05it/s]\n",
      " 98%|█████████▊| 246/250 [00:40<00:00,  7.41it/s]\n",
      " 99%|█████████▉| 247/250 [00:41<00:00,  4.02it/s]\n",
      "100%|█████████▉| 249/250 [00:41<00:00,  4.22it/s]\n",
      "100%|██████████| 250/250 [00:41<00:00,  4.78it/s]\n",
      "100%|██████████| 250/250 [00:41<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 124 --verify_dataset_integrity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Preprocessed Data verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad files: []\n",
      "Count: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "folder = r\"D:\\Capstone\\Experiment 3\\nnUNet_preprocessed\\Dataset123_ISLES22\\nnUNetPlans_3d_fullres\"\n",
    "\n",
    "bad = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".npz\"):\n",
    "        path = os.path.join(folder, file)\n",
    "        try:\n",
    "            _ = np.load(path)\n",
    "        except Exception as e:\n",
    "            bad.append((file, str(e)))\n",
    "\n",
    "print(\"Bad files:\", bad)\n",
    "print(\"Count:\", len(bad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: 3D Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Restrict number of CPU workers to avoid crashes\n",
    "os.environ[\"nnUNet_n_proc_lowres\"] = \"1\"\n",
    "os.environ[\"nnUNet_n_proc_fullres\"] = \"1\"\n",
    "os.environ[\"nnUNet_num_threads\"] = \"1\"\n",
    "os.environ[\"nnUNet_num_gpus\"] = \"1\"\n",
    "\n",
    "# reduce dataloader workers\n",
    "os.environ[\"nnUNet_dataloader_num_workers\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-09 15:57:17.167474: do_dummy_2d_data_aug: False\n",
      "2025-11-09 15:57:17.169924: Using splits from existing split file: D:\\Capstone\\Experiment 3\\nnUNet_preprocessed\\Dataset123_ISLES22\\splits_final.json\n",
      "2025-11-09 15:57:17.170921: The split file contains 5 splits.\n",
      "2025-11-09 15:57:17.171923: Desired fold for training: 0\n",
      "2025-11-09 15:57:17.171923: This split has 200 training and 50 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [80, 112, 112], 'median_image_size_in_voxels': [72.0, 112.0, 112.0], 'spacing': [2.0, 2.0, 2.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset123_ISLES22', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 2.0, 2.0], 'original_median_shape_after_transp': [72, 112, 112], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2117.0, 'mean': 374.9803381258754, 'median': 356.0013427734375, 'min': 6.620041403948562e-06, 'percentile_00_5': 89.99862670898438, 'percentile_99_5': 878.9948120117188, 'std': 156.9442956212566}, '1': {'max': 4506.12158203125, 'mean': 222.5365358402489, 'median': 0.5183995962142944, 'min': -319.0020751953125, 'percentile_00_5': 0.00027764352853409946, 'percentile_99_5': 1673.6614990234375, 'std': 375.24569493155883}, '2': {'max': 5049.42724609375, 'mean': 1166.910578771508, 'median': 1260.6309814453125, 'min': -575.469482421875, 'percentile_00_5': 71.0, 'percentile_99_5': 2330.02392578125, 'std': 570.0462245514832}}} \n",
      "\n",
      "2025-11-09 15:58:03.399534: unpacking dataset...\n",
      "2025-11-09 15:58:10.977197: unpacking done...\n",
      "2025-11-09 15:58:10.984727: Unable to plot network architecture:\n",
      "2025-11-09 15:58:10.984727: No module named 'hiddenlayer'\n",
      "2025-11-09 15:58:11.047449: \n",
      "2025-11-09 15:58:11.048956: Epoch 0\n",
      "2025-11-09 15:58:11.048956: Current learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\"nnUNetv2_train\", \"123\", \"3d_fullres\", \"0\"]\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line, end=\"\")\n",
    "\n",
    "process.wait()\n",
    "print(\"\\nExit code:\", process.returncode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Training 2D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import nnunetv2.training.nnUNetTrainer as T\n",
    "print(T.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nnUNetTrainer_2d_200epochs']\n"
     ]
    }
   ],
   "source": [
    "import nnunetv2.training.nnUNetTrainer as T\n",
    "print([c for c in dir(T) if \"200\" in c.lower()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-09 23:22:48.129381: do_dummy_2d_data_aug: False\n",
      "2025-11-09 23:22:48.131897: Using splits from existing split file: D:\\Capstone\\Experiment 3\\nnUNet_preprocessed\\Dataset123_ISLES22\\splits_final.json\n",
      "2025-11-09 23:22:48.132899: The split file contains 5 splits.\n",
      "2025-11-09 23:22:48.132899: Desired fold for training: 0\n",
      "2025-11-09 23:22:48.133907: This split has 200 training and 50 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 266, 'patch_size': [112, 112], 'median_image_size_in_voxels': [112.0, 112.0], 'spacing': [2.0, 2.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset123_ISLES22', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 2.0, 2.0], 'original_median_shape_after_transp': [72, 112, 112], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2117.0, 'mean': 374.9803381258754, 'median': 356.0013427734375, 'min': 6.620041403948562e-06, 'percentile_00_5': 89.99862670898438, 'percentile_99_5': 878.9948120117188, 'std': 156.9442956212566}, '1': {'max': 4506.12158203125, 'mean': 222.5365358402489, 'median': 0.5183995962142944, 'min': -319.0020751953125, 'percentile_00_5': 0.00027764352853409946, 'percentile_99_5': 1673.6614990234375, 'std': 375.24569493155883}, '2': {'max': 5049.42724609375, 'mean': 1166.910578771508, 'median': 1260.6309814453125, 'min': -575.469482421875, 'percentile_00_5': 71.0, 'percentile_99_5': 2330.02392578125, 'std': 570.0462245514832}}} \n",
      "\n",
      "2025-11-09 23:23:14.618165: unpacking dataset...\n",
      "2025-11-09 23:23:15.856408: unpacking done...\n",
      "2025-11-09 23:23:15.865379: Unable to plot network architecture:\n",
      "2025-11-09 23:23:15.866378: No module named 'hiddenlayer'\n",
      "2025-11-09 23:23:15.927247: \n",
      "2025-11-09 23:23:15.928245: Epoch 0\n",
      "2025-11-09 23:23:15.929254: Current learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\"nnUNetv2_train\", \"123\", \"2d\", \"0\"]  # dataset 123, 2D model, GPU 0\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(line, end=\"\")\n",
    "\n",
    "process.wait()\n",
    "print(\"\\nTraining finished with exit code:\", process.returncode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-26 23:52:53.475369: do_dummy_2d_data_aug: False\n",
      "2025-11-26 23:52:53.478899: Creating new 5-fold cross-validation split...\n",
      "2025-11-26 23:52:53.481902: Desired fold for training: 0\n",
      "2025-11-26 23:52:53.481902: This split has 200 training and 50 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 266, 'patch_size': [112, 112], 'median_image_size_in_voxels': [112.0, 112.0], 'spacing': [2.0, 2.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset124_ISLES22_2CH', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 2.0, 2.0], 'original_median_shape_after_transp': [72, 112, 112], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2117.0, 'mean': 374.9803381258754, 'median': 356.0013427734375, 'min': 6.620041403948562e-06, 'percentile_00_5': 89.99862670898438, 'percentile_99_5': 878.9948120117188, 'std': 156.9442956212566}, '1': {'max': 4506.12158203125, 'mean': 222.5365358402489, 'median': 0.5183995962142944, 'min': -319.0020751953125, 'percentile_00_5': 0.00027764352853409946, 'percentile_99_5': 1673.6614990234375, 'std': 375.24569493155883}}} \n",
      "\n",
      "2025-11-26 23:54:20.922517: unpacking dataset...\n",
      "2025-11-26 23:54:27.336018: unpacking done...\n",
      "2025-11-26 23:54:27.343551: Unable to plot network architecture:\n",
      "2025-11-26 23:54:27.343551: No module named 'hiddenlayer'\n",
      "2025-11-26 23:54:27.404928: \n",
      "2025-11-26 23:54:27.405938: Epoch 0\n",
      "2025-11-26 23:54:27.405938: Current learning rate: 0.01\n",
      "2025-11-27 00:26:14.506189: train_loss -0.4864\n",
      "2025-11-27 00:26:14.507189: val_loss -0.738\n",
      "2025-11-27 00:26:14.508194: Pseudo dice [0.7751]\n",
      "2025-11-27 00:26:14.508194: Epoch time: 1907.1 s\n",
      "2025-11-27 00:26:14.659918: Yayy! New best EMA pseudo Dice: 0.7751\n",
      "2025-11-27 00:26:15.852369: \n",
      "2025-11-27 00:26:15.853900: Epoch 1\n",
      "2025-11-27 00:26:15.853900: Current learning rate: 0.00955\n",
      "2025-11-27 00:54:27.383113: train_loss -0.7771\n",
      "2025-11-27 00:54:27.384112: val_loss -0.7924\n",
      "2025-11-27 00:54:27.384112: Pseudo dice [0.8179]\n",
      "2025-11-27 00:54:27.385112: Epoch time: 1691.53 s\n",
      "2025-11-27 00:54:27.531832: Yayy! New best EMA pseudo Dice: 0.7794\n",
      "2025-11-27 00:54:29.241914: \n",
      "2025-11-27 00:54:29.242424: Epoch 2\n",
      "2025-11-27 00:54:29.242424: Current learning rate: 0.0091\n",
      "2025-11-27 01:22:36.315454: train_loss -0.8148\n",
      "2025-11-27 01:22:36.316460: val_loss -0.7936\n",
      "2025-11-27 01:22:36.317475: Pseudo dice [0.8175]\n",
      "2025-11-27 01:22:36.317475: Epoch time: 1687.07 s\n",
      "2025-11-27 01:22:36.465017: Yayy! New best EMA pseudo Dice: 0.7832\n",
      "2025-11-27 01:22:37.960255: \n",
      "2025-11-27 01:22:37.961253: Epoch 3\n",
      "2025-11-27 01:22:37.961253: Current learning rate: 0.00864\n",
      "2025-11-27 01:50:45.216342: train_loss -0.8329\n",
      "2025-11-27 01:50:45.217342: val_loss -0.8107\n",
      "2025-11-27 01:50:45.217342: Pseudo dice [0.8325]\n",
      "2025-11-27 01:50:45.217342: Epoch time: 1687.26 s\n",
      "2025-11-27 01:50:45.354382: Yayy! New best EMA pseudo Dice: 0.7881\n",
      "2025-11-27 01:50:46.790232: \n",
      "2025-11-27 01:50:46.790232: Epoch 4\n",
      "2025-11-27 01:50:46.790232: Current learning rate: 0.00818\n",
      "2025-11-27 02:18:54.216690: train_loss -0.8483\n",
      "2025-11-27 02:18:54.217695: val_loss -0.8125\n",
      "2025-11-27 02:18:54.217695: Pseudo dice [0.8328]\n",
      "2025-11-27 02:18:54.217695: Epoch time: 1687.43 s\n",
      "2025-11-27 02:18:54.376632: Yayy! New best EMA pseudo Dice: 0.7926\n",
      "2025-11-27 02:18:55.912992: \n",
      "2025-11-27 02:18:55.913984: Epoch 5\n",
      "2025-11-27 02:18:55.913984: Current learning rate: 0.00772\n",
      "2025-11-27 02:47:03.079482: train_loss -0.8561\n",
      "2025-11-27 02:47:03.079482: val_loss -0.818\n",
      "2025-11-27 02:47:03.080487: Pseudo dice [0.8383]\n",
      "2025-11-27 02:47:03.080487: Epoch time: 1687.17 s\n",
      "2025-11-27 02:47:03.243354: Yayy! New best EMA pseudo Dice: 0.7972\n",
      "2025-11-27 02:47:04.560730: \n",
      "2025-11-27 02:47:04.560730: Epoch 6\n",
      "2025-11-27 02:47:04.561740: Current learning rate: 0.00725\n",
      "2025-11-27 03:15:11.899600: train_loss -0.863\n",
      "2025-11-27 03:15:11.899600: val_loss -0.8089\n",
      "2025-11-27 03:15:11.901112: Pseudo dice [0.8291]\n",
      "2025-11-27 03:15:11.901112: Epoch time: 1687.34 s\n",
      "2025-11-27 03:15:12.076208: Yayy! New best EMA pseudo Dice: 0.8003\n",
      "2025-11-27 03:15:13.427936: \n",
      "2025-11-27 03:15:13.427936: Epoch 7\n",
      "2025-11-27 03:15:13.428937: Current learning rate: 0.00679\n",
      "2025-11-27 03:43:20.677991: train_loss -0.8694\n",
      "2025-11-27 03:43:20.677991: val_loss -0.8238\n",
      "2025-11-27 03:43:20.678992: Pseudo dice [0.8435]\n",
      "2025-11-27 03:43:20.678992: Epoch time: 1687.25 s\n",
      "2025-11-27 03:43:20.833031: Yayy! New best EMA pseudo Dice: 0.8047\n",
      "2025-11-27 03:43:22.260106: \n",
      "2025-11-27 03:43:22.260106: Epoch 8\n",
      "2025-11-27 03:43:22.261136: Current learning rate: 0.00631\n",
      "2025-11-27 04:11:30.566728: train_loss -0.8744\n",
      "2025-11-27 04:11:30.566728: val_loss -0.8273\n",
      "2025-11-27 04:11:30.568376: Pseudo dice [0.8465]\n",
      "2025-11-27 04:11:30.568376: Epoch time: 1688.31 s\n",
      "2025-11-27 04:11:30.701516: Yayy! New best EMA pseudo Dice: 0.8089\n",
      "2025-11-27 04:11:32.354627: \n",
      "2025-11-27 04:11:32.354627: Epoch 9\n",
      "2025-11-27 04:11:32.355625: Current learning rate: 0.00584\n",
      "2025-11-27 04:39:39.738253: train_loss -0.8766\n",
      "2025-11-27 04:39:39.739250: val_loss -0.8266\n",
      "2025-11-27 04:39:39.739250: Pseudo dice [0.8473]\n",
      "2025-11-27 04:39:39.740247: Epoch time: 1687.38 s\n",
      "2025-11-27 04:39:39.896074: Yayy! New best EMA pseudo Dice: 0.8127\n",
      "2025-11-27 04:39:41.184761: \n",
      "2025-11-27 04:39:41.186286: Epoch 10\n",
      "2025-11-27 04:39:41.186286: Current learning rate: 0.00536\n",
      "2025-11-27 05:07:48.758174: train_loss -0.8809\n",
      "2025-11-27 05:07:48.758174: val_loss -0.82\n",
      "2025-11-27 05:07:48.758174: Pseudo dice [0.8398]\n",
      "2025-11-27 05:07:48.759197: Epoch time: 1687.57 s\n",
      "2025-11-27 05:07:48.907141: Yayy! New best EMA pseudo Dice: 0.8154\n",
      "2025-11-27 05:07:50.248001: \n",
      "2025-11-27 05:07:50.248001: Epoch 11\n",
      "2025-11-27 05:07:50.248001: Current learning rate: 0.00487\n",
      "2025-11-27 05:35:57.515866: train_loss -0.8824\n",
      "2025-11-27 05:35:57.515866: val_loss -0.8237\n",
      "2025-11-27 05:35:57.516880: Pseudo dice [0.8427]\n",
      "2025-11-27 05:35:57.517883: Epoch time: 1687.27 s\n",
      "2025-11-27 05:35:57.670030: Yayy! New best EMA pseudo Dice: 0.8181\n",
      "2025-11-27 05:35:59.014924: \n",
      "2025-11-27 05:35:59.014924: Epoch 12\n",
      "2025-11-27 05:35:59.014924: Current learning rate: 0.00438\n",
      "2025-11-27 06:04:06.455529: train_loss -0.8861\n",
      "2025-11-27 06:04:06.456530: val_loss -0.8284\n",
      "2025-11-27 06:04:06.457534: Pseudo dice [0.8471]\n",
      "2025-11-27 06:04:06.457534: Epoch time: 1687.44 s\n",
      "2025-11-27 06:04:06.597292: Yayy! New best EMA pseudo Dice: 0.821\n",
      "2025-11-27 06:04:07.941734: \n",
      "2025-11-27 06:04:07.943258: Epoch 13\n",
      "2025-11-27 06:04:07.943258: Current learning rate: 0.00389\n",
      "2025-11-27 06:32:15.857485: train_loss -0.8865\n",
      "2025-11-27 06:32:15.858501: val_loss -0.8237\n",
      "2025-11-27 06:32:15.858501: Pseudo dice [0.8427]\n",
      "2025-11-27 06:32:15.858501: Epoch time: 1687.92 s\n",
      "2025-11-27 06:32:16.000875: Yayy! New best EMA pseudo Dice: 0.8232\n",
      "2025-11-27 06:32:17.371951: \n",
      "2025-11-27 06:32:17.372956: Epoch 14\n",
      "2025-11-27 06:32:17.372956: Current learning rate: 0.00338\n",
      "2025-11-27 07:00:25.125977: train_loss -0.8886\n",
      "2025-11-27 07:00:25.125977: val_loss -0.827\n",
      "2025-11-27 07:00:25.127488: Pseudo dice [0.8457]\n",
      "2025-11-27 07:00:25.127488: Epoch time: 1687.76 s\n",
      "2025-11-27 07:00:25.554884: Yayy! New best EMA pseudo Dice: 0.8255\n",
      "2025-11-27 07:00:26.887692: \n",
      "2025-11-27 07:00:26.887692: Epoch 15\n",
      "2025-11-27 07:00:26.887692: Current learning rate: 0.00287\n",
      "2025-11-27 07:28:36.473048: train_loss -0.8908\n",
      "2025-11-27 07:28:36.473048: val_loss -0.8246\n",
      "2025-11-27 07:28:36.474058: Pseudo dice [0.8432]\n",
      "2025-11-27 07:28:36.474058: Epoch time: 1689.59 s\n",
      "2025-11-27 07:28:36.609777: Yayy! New best EMA pseudo Dice: 0.8272\n",
      "2025-11-27 07:28:37.980205: \n",
      "2025-11-27 07:28:37.981208: Epoch 16\n",
      "2025-11-27 07:28:37.981208: Current learning rate: 0.00235\n",
      "2025-11-27 07:56:45.935508: train_loss -0.893\n",
      "2025-11-27 07:56:45.936503: val_loss -0.8309\n",
      "2025-11-27 07:56:45.936503: Pseudo dice [0.8493]\n",
      "2025-11-27 07:56:45.937504: Epoch time: 1687.96 s\n",
      "2025-11-27 07:56:46.082191: Yayy! New best EMA pseudo Dice: 0.8294\n",
      "2025-11-27 07:56:47.531525: \n",
      "2025-11-27 07:56:47.531525: Epoch 17\n",
      "2025-11-27 07:56:47.531525: Current learning rate: 0.00181\n",
      "2025-11-27 08:24:55.093042: train_loss -0.8936\n",
      "2025-11-27 08:24:55.094043: val_loss -0.8246\n",
      "2025-11-27 08:24:55.094043: Pseudo dice [0.843]\n",
      "2025-11-27 08:24:55.095067: Epoch time: 1687.56 s\n",
      "2025-11-27 08:24:55.269168: Yayy! New best EMA pseudo Dice: 0.8308\n",
      "2025-11-27 08:24:56.731350: \n",
      "2025-11-27 08:24:56.732261: Epoch 18\n",
      "2025-11-27 08:24:56.732261: Current learning rate: 0.00126\n",
      "2025-11-27 08:53:06.810614: train_loss -0.8956\n",
      "2025-11-27 08:53:06.810614: val_loss -0.828\n",
      "2025-11-27 08:53:06.812121: Pseudo dice [0.8472]\n",
      "2025-11-27 08:53:06.812121: Epoch time: 1690.08 s\n",
      "2025-11-27 08:53:06.983055: Yayy! New best EMA pseudo Dice: 0.8324\n",
      "2025-11-27 08:53:08.290452: \n",
      "2025-11-27 08:53:08.290452: Epoch 19\n",
      "2025-11-27 08:53:08.291457: Current learning rate: 0.00067\n",
      "2025-11-27 09:21:19.600693: train_loss -0.8967\n",
      "2025-11-27 09:21:19.601695: val_loss -0.8267\n",
      "2025-11-27 09:21:19.601695: Pseudo dice [0.8449]\n",
      "2025-11-27 09:21:19.601695: Epoch time: 1691.31 s\n",
      "2025-11-27 09:21:19.603210: Yayy! New best EMA pseudo Dice: 0.8337\n",
      "2025-11-27 09:21:21.773833: Training done.\n",
      "2025-11-27 09:21:21.890302: Using splits from existing split file: D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_preprocessed\\Dataset124_ISLES22_2CH\\splits_final.json\n",
      "2025-11-27 09:21:21.893333: The split file contains 5 splits.\n",
      "2025-11-27 09:21:21.893333: Desired fold for training: 0\n",
      "2025-11-27 09:21:21.894327: This split has 200 training and 50 validation cases.\n",
      "2025-11-27 09:21:21.896336: predicting ISLES22_0010\n",
      "2025-11-27 09:21:21.903866: ISLES22_0010, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:21:25.339038: predicting ISLES22_0011\n",
      "2025-11-27 09:21:25.343542: ISLES22_0011, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:21:28.924476: predicting ISLES22_0017\n",
      "2025-11-27 09:21:28.929988: ISLES22_0017, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:21:32.967194: predicting ISLES22_0019\n",
      "2025-11-27 09:21:32.973717: ISLES22_0019, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:21:37.322340: predicting ISLES22_0021\n",
      "2025-11-27 09:21:37.327355: ISLES22_0021, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:21:41.385590: predicting ISLES22_0028\n",
      "2025-11-27 09:21:41.390585: ISLES22_0028, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:21:45.057795: predicting ISLES22_0031\n",
      "2025-11-27 09:21:45.062809: ISLES22_0031, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:21:48.980753: predicting ISLES22_0034\n",
      "2025-11-27 09:21:48.984769: ISLES22_0034, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:21:52.809186: predicting ISLES22_0041\n",
      "2025-11-27 09:21:52.814189: ISLES22_0041, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:21:56.263940: predicting ISLES22_0048\n",
      "2025-11-27 09:21:56.271510: ISLES22_0048, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:21:58.740574: predicting ISLES22_0051\n",
      "2025-11-27 09:21:58.744568: ISLES22_0051, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:01.207572: predicting ISLES22_0053\n",
      "2025-11-27 09:22:01.212088: ISLES22_0053, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:03.227104: predicting ISLES22_0055\n",
      "2025-11-27 09:22:03.230619: ISLES22_0055, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:05.283111: predicting ISLES22_0068\n",
      "2025-11-27 09:22:05.286624: ISLES22_0068, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:07.287846: predicting ISLES22_0069\n",
      "2025-11-27 09:22:07.291848: ISLES22_0069, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:09.301854: predicting ISLES22_0072\n",
      "2025-11-27 09:22:09.305855: ISLES22_0072, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:11.321710: predicting ISLES22_0074\n",
      "2025-11-27 09:22:11.325225: ISLES22_0074, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:13.382278: predicting ISLES22_0086\n",
      "2025-11-27 09:22:13.386791: ISLES22_0086, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:15.437652: predicting ISLES22_0093\n",
      "2025-11-27 09:22:15.441165: ISLES22_0093, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:17.434571: predicting ISLES22_0094\n",
      "2025-11-27 09:22:17.438089: ISLES22_0094, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:19.472241: predicting ISLES22_0104\n",
      "2025-11-27 09:22:19.476757: ISLES22_0104, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:21.511809: predicting ISLES22_0105\n",
      "2025-11-27 09:22:21.515815: ISLES22_0105, shape torch.Size([2, 72, 128, 128]), rank 0\n",
      "2025-11-27 09:22:29.367829: predicting ISLES22_0110\n",
      "2025-11-27 09:22:29.371839: ISLES22_0110, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:31.445166: predicting ISLES22_0118\n",
      "2025-11-27 09:22:31.448166: ISLES22_0118, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:33.475115: predicting ISLES22_0121\n",
      "2025-11-27 09:22:33.478117: ISLES22_0121, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:35.523926: predicting ISLES22_0123\n",
      "2025-11-27 09:22:35.527436: ISLES22_0123, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:37.605209: predicting ISLES22_0135\n",
      "2025-11-27 09:22:37.608724: ISLES22_0135, shape torch.Size([2, 74, 112, 112]), rank 0\n",
      "2025-11-27 09:22:39.717987: predicting ISLES22_0137\n",
      "2025-11-27 09:22:39.722500: ISLES22_0137, shape torch.Size([2, 33, 115, 115]), rank 0\n",
      "2025-11-27 09:22:43.317129: predicting ISLES22_0140\n",
      "2025-11-27 09:22:43.320131: ISLES22_0140, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:45.415739: predicting ISLES22_0146\n",
      "2025-11-27 09:22:45.419245: ISLES22_0146, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:47.447201: predicting ISLES22_0148\n",
      "2025-11-27 09:22:47.450204: ISLES22_0148, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:49.509204: predicting ISLES22_0151\n",
      "2025-11-27 09:22:49.512717: ISLES22_0151, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:22:51.542117: predicting ISLES22_0160\n",
      "2025-11-27 09:22:51.546653: ISLES22_0160, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:53.591340: predicting ISLES22_0161\n",
      "2025-11-27 09:22:53.595345: ISLES22_0161, shape torch.Size([2, 25, 115, 115]), rank 0\n",
      "2025-11-27 09:22:56.327245: predicting ISLES22_0168\n",
      "2025-11-27 09:22:56.330250: ISLES22_0168, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:22:58.349286: predicting ISLES22_0181\n",
      "2025-11-27 09:22:58.354319: ISLES22_0181, shape torch.Size([2, 76, 112, 112]), rank 0\n",
      "2025-11-27 09:23:00.476859: predicting ISLES22_0182\n",
      "2025-11-27 09:23:00.481377: ISLES22_0182, shape torch.Size([2, 25, 115, 115]), rank 0\n",
      "2025-11-27 09:23:03.266926: predicting ISLES22_0186\n",
      "2025-11-27 09:23:03.268925: ISLES22_0186, shape torch.Size([2, 25, 115, 115]), rank 0\n",
      "2025-11-27 09:23:06.093132: predicting ISLES22_0187\n",
      "2025-11-27 09:23:06.096658: ISLES22_0187, shape torch.Size([2, 25, 115, 115]), rank 0\n",
      "2025-11-27 09:23:08.834701: predicting ISLES22_0188\n",
      "2025-11-27 09:23:08.836700: ISLES22_0188, shape torch.Size([2, 30, 110, 110]), rank 0\n",
      "2025-11-27 09:23:09.718727: predicting ISLES22_0196\n",
      "2025-11-27 09:23:09.721233: ISLES22_0196, shape torch.Size([2, 73, 112, 112]), rank 0\n",
      "2025-11-27 09:23:11.745471: predicting ISLES22_0197\n",
      "2025-11-27 09:23:11.748984: ISLES22_0197, shape torch.Size([2, 25, 115, 115]), rank 0\n",
      "2025-11-27 09:23:14.480436: predicting ISLES22_0201\n",
      "2025-11-27 09:23:14.482947: ISLES22_0201, shape torch.Size([2, 63, 120, 120]), rank 0\n",
      "2025-11-27 09:23:21.365683: predicting ISLES22_0205\n",
      "2025-11-27 09:23:21.370203: ISLES22_0205, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:23:23.405165: predicting ISLES22_0207\n",
      "2025-11-27 09:23:23.408681: ISLES22_0207, shape torch.Size([2, 30, 110, 110]), rank 0\n",
      "2025-11-27 09:23:24.261273: predicting ISLES22_0212\n",
      "2025-11-27 09:23:24.264782: ISLES22_0212, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:23:26.264782: predicting ISLES22_0220\n",
      "2025-11-27 09:23:26.268296: ISLES22_0220, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:23:28.290329: predicting ISLES22_0235\n",
      "2025-11-27 09:23:28.293838: ISLES22_0235, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:23:30.303535: predicting ISLES22_0238\n",
      "2025-11-27 09:23:30.308621: ISLES22_0238, shape torch.Size([2, 30, 110, 110]), rank 0\n",
      "2025-11-27 09:23:31.185528: predicting ISLES22_0247\n",
      "2025-11-27 09:23:31.188040: ISLES22_0247, shape torch.Size([2, 72, 112, 112]), rank 0\n",
      "2025-11-27 09:23:41.309021: Validation complete\n",
      "2025-11-27 09:23:41.309021: Mean Validation Dice:  0.7563915900103954\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 124 2d 0 -device cuda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-16 17:01:20.501065: do_dummy_2d_data_aug: False\n",
      "2025-11-16 17:01:20.505572: Using splits from existing split file: D:\\Capstone\\Experiment 3\\nnUNet_preprocessed\\Dataset123_ISLES22\\splits_final.json\n",
      "2025-11-16 17:01:20.507583: The split file contains 5 splits.\n",
      "2025-11-16 17:01:20.507583: Desired fold for training: 0\n",
      "2025-11-16 17:01:20.507583: This split has 200 training and 50 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 266, 'patch_size': [112, 112], 'median_image_size_in_voxels': [112.0, 112.0], 'spacing': [2.0, 2.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset123_ISLES22', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 2.0, 2.0], 'original_median_shape_after_transp': [72, 112, 112], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2117.0, 'mean': 374.9803381258754, 'median': 356.0013427734375, 'min': 6.620041403948562e-06, 'percentile_00_5': 89.99862670898438, 'percentile_99_5': 878.9948120117188, 'std': 156.9442956212566}, '1': {'max': 4506.12158203125, 'mean': 222.5365358402489, 'median': 0.5183995962142944, 'min': -319.0020751953125, 'percentile_00_5': 0.00027764352853409946, 'percentile_99_5': 1673.6614990234375, 'std': 375.24569493155883}, '2': {'max': 5049.42724609375, 'mean': 1166.910578771508, 'median': 1260.6309814453125, 'min': -575.469482421875, 'percentile_00_5': 71.0, 'percentile_99_5': 2330.02392578125, 'std': 570.0462245514832}}} \n",
      "\n",
      "2025-11-16 17:01:46.961498: unpacking dataset...\n",
      "2025-11-16 17:01:48.663327: unpacking done...\n",
      "2025-11-16 17:01:48.671915: Unable to plot network architecture:\n",
      "2025-11-16 17:01:48.671915: No module named 'hiddenlayer'\n",
      "2025-11-16 17:01:48.786142: \n",
      "2025-11-16 17:01:48.786142: Epoch 172\n",
      "2025-11-16 17:01:48.787653: Current learning rate: 0.0017\n",
      "2025-11-16 17:38:45.259983: train_loss -0.949\n",
      "2025-11-16 17:38:45.262998: val_loss -0.8264\n",
      "2025-11-16 17:38:45.263998: Pseudo dice [0.8452]\n",
      "2025-11-16 17:38:45.263998: Epoch time: 2216.47 s\n",
      "2025-11-16 17:38:47.065410: \n",
      "2025-11-16 17:38:47.065410: Epoch 173\n",
      "2025-11-16 17:38:47.066414: Current learning rate: 0.00165\n",
      "2025-11-16 18:12:47.180121: train_loss -0.9497\n",
      "2025-11-16 18:12:47.181121: val_loss -0.8247\n",
      "2025-11-16 18:12:47.181121: Pseudo dice [0.8424]\n",
      "2025-11-16 18:12:47.182127: Epoch time: 2040.12 s\n",
      "2025-11-16 18:12:49.541903: \n",
      "2025-11-16 18:12:49.542902: Epoch 174\n",
      "2025-11-16 18:12:49.542902: Current learning rate: 0.00159\n",
      "2025-11-16 18:46:18.656250: train_loss -0.9498\n",
      "2025-11-16 18:46:18.656250: val_loss -0.8227\n",
      "2025-11-16 18:46:18.657547: Pseudo dice [0.8405]\n",
      "2025-11-16 18:46:18.658537: Epoch time: 2009.12 s\n",
      "2025-11-16 18:46:19.871289: \n",
      "2025-11-16 18:46:19.871289: Epoch 175\n",
      "2025-11-16 18:46:19.872279: Current learning rate: 0.00154\n",
      "2025-11-16 19:20:15.067862: train_loss -0.9498\n",
      "2025-11-16 19:20:15.068872: val_loss -0.8261\n",
      "2025-11-16 19:20:15.068872: Pseudo dice [0.8443]\n",
      "2025-11-16 19:20:15.068872: Epoch time: 2035.2 s\n",
      "2025-11-16 19:20:16.298379: \n",
      "2025-11-16 19:20:16.298379: Epoch 176\n",
      "2025-11-16 19:20:16.299378: Current learning rate: 0.00148\n",
      "2025-11-16 19:54:11.414946: train_loss -0.9498\n",
      "2025-11-16 19:54:11.415945: val_loss -0.828\n",
      "2025-11-16 19:54:11.415945: Pseudo dice [0.8464]\n",
      "2025-11-16 19:54:11.415945: Epoch time: 2035.12 s\n",
      "2025-11-16 19:54:12.636976: \n",
      "2025-11-16 19:54:12.637980: Epoch 177\n",
      "2025-11-16 19:54:12.637980: Current learning rate: 0.00143\n",
      "2025-11-16 20:28:08.263688: train_loss -0.9503\n",
      "2025-11-16 20:28:08.265196: val_loss -0.8169\n",
      "2025-11-16 20:28:08.266207: Pseudo dice [0.8369]\n",
      "2025-11-16 20:28:08.266207: Epoch time: 2035.63 s\n",
      "2025-11-16 20:28:09.526148: \n",
      "2025-11-16 20:28:09.526148: Epoch 178\n",
      "2025-11-16 20:28:09.527143: Current learning rate: 0.00137\n",
      "2025-11-16 21:10:32.174783: train_loss -0.9498\n",
      "2025-11-16 21:10:32.175781: val_loss -0.817\n",
      "2025-11-16 21:10:32.175781: Pseudo dice [0.8369]\n",
      "2025-11-16 21:10:32.176782: Epoch time: 2542.65 s\n",
      "2025-11-16 21:10:33.361128: \n",
      "2025-11-16 21:10:33.361128: Epoch 179\n",
      "2025-11-16 21:10:33.361128: Current learning rate: 0.00132\n",
      "2025-11-16 21:44:17.632224: train_loss -0.9497\n",
      "2025-11-16 21:44:17.633217: val_loss -0.8225\n",
      "2025-11-16 21:44:17.633217: Pseudo dice [0.8407]\n",
      "2025-11-16 21:44:17.634217: Epoch time: 2024.27 s\n",
      "2025-11-16 21:44:18.893540: \n",
      "2025-11-16 21:44:18.893540: Epoch 180\n",
      "2025-11-16 21:44:18.894570: Current learning rate: 0.00126\n",
      "2025-11-16 22:18:13.886695: train_loss -0.9506\n",
      "2025-11-16 22:18:13.886695: val_loss -0.8283\n",
      "2025-11-16 22:18:13.887696: Pseudo dice [0.8466]\n",
      "2025-11-16 22:18:13.887696: Epoch time: 2034.99 s\n",
      "2025-11-16 22:18:16.194859: \n",
      "2025-11-16 22:18:16.194859: Epoch 181\n",
      "2025-11-16 22:18:16.194859: Current learning rate: 0.0012\n",
      "2025-11-16 22:52:10.116934: train_loss -0.9503\n",
      "2025-11-16 22:52:10.117939: val_loss -0.8261\n",
      "2025-11-16 22:52:10.117939: Pseudo dice [0.8451]\n",
      "2025-11-16 22:52:10.117939: Epoch time: 2033.92 s\n",
      "2025-11-16 22:52:11.330909: \n",
      "2025-11-16 22:52:11.331923: Epoch 182\n",
      "2025-11-16 22:52:11.331923: Current learning rate: 0.00115\n",
      "2025-11-16 23:26:05.926462: train_loss -0.9503\n",
      "2025-11-16 23:26:05.926968: val_loss -0.8229\n",
      "2025-11-16 23:26:05.926968: Pseudo dice [0.8415]\n",
      "2025-11-16 23:26:05.927985: Epoch time: 2034.6 s\n",
      "2025-11-16 23:26:07.164554: \n",
      "2025-11-16 23:26:07.165555: Epoch 183\n",
      "2025-11-16 23:26:07.165555: Current learning rate: 0.00109\n",
      "2025-11-16 23:59:48.438632: train_loss -0.9508\n",
      "2025-11-16 23:59:48.439642: val_loss -0.8238\n",
      "2025-11-16 23:59:48.439642: Pseudo dice [0.8437]\n",
      "2025-11-16 23:59:48.440646: Epoch time: 2021.28 s\n",
      "2025-11-16 23:59:49.673773: \n",
      "2025-11-16 23:59:49.673773: Epoch 184\n",
      "2025-11-16 23:59:49.674772: Current learning rate: 0.00103\n",
      "2025-11-17 00:33:44.025831: train_loss -0.9509\n",
      "2025-11-17 00:33:44.026843: val_loss -0.8205\n",
      "2025-11-17 00:33:44.027327: Pseudo dice [0.8392]\n",
      "2025-11-17 00:33:44.028341: Epoch time: 2034.35 s\n",
      "2025-11-17 00:33:45.260822: \n",
      "2025-11-17 00:33:45.260822: Epoch 185\n",
      "2025-11-17 00:33:45.260822: Current learning rate: 0.00097\n",
      "2025-11-17 01:07:40.060444: train_loss -0.951\n",
      "2025-11-17 01:07:40.060444: val_loss -0.8224\n",
      "2025-11-17 01:07:40.061444: Pseudo dice [0.8411]\n",
      "2025-11-17 01:07:40.061444: Epoch time: 2034.8 s\n",
      "2025-11-17 01:07:41.261030: \n",
      "2025-11-17 01:07:41.262030: Epoch 186\n",
      "2025-11-17 01:07:41.262030: Current learning rate: 0.00091\n",
      "2025-11-17 01:41:35.827714: train_loss -0.9516\n",
      "2025-11-17 01:41:35.828722: val_loss -0.8237\n",
      "2025-11-17 01:41:35.828722: Pseudo dice [0.8431]\n",
      "2025-11-17 01:41:35.828722: Epoch time: 2034.57 s\n",
      "2025-11-17 01:41:37.459636: \n",
      "2025-11-17 01:41:37.459636: Epoch 187\n",
      "2025-11-17 01:41:37.460637: Current learning rate: 0.00085\n",
      "2025-11-17 02:15:33.115979: train_loss -0.9512\n",
      "2025-11-17 02:15:33.117977: val_loss -0.8276\n",
      "2025-11-17 02:15:33.117977: Pseudo dice [0.8458]\n",
      "2025-11-17 02:15:33.117977: Epoch time: 2035.66 s\n",
      "2025-11-17 02:15:34.296985: \n",
      "2025-11-17 02:15:34.296985: Epoch 188\n",
      "2025-11-17 02:15:34.297986: Current learning rate: 0.00079\n",
      "2025-11-17 02:49:29.320948: train_loss -0.9514\n",
      "2025-11-17 02:49:29.321953: val_loss -0.8284\n",
      "2025-11-17 02:49:29.321953: Pseudo dice [0.8469]\n",
      "2025-11-17 02:49:29.321953: Epoch time: 2035.02 s\n",
      "2025-11-17 02:49:30.618847: \n",
      "2025-11-17 02:49:30.619844: Epoch 189\n",
      "2025-11-17 02:49:30.619844: Current learning rate: 0.00074\n",
      "2025-11-17 03:23:24.757564: train_loss -0.9515\n",
      "2025-11-17 03:23:24.758568: val_loss -0.8213\n",
      "2025-11-17 03:23:24.758568: Pseudo dice [0.8407]\n",
      "2025-11-17 03:23:24.759563: Epoch time: 2034.14 s\n",
      "2025-11-17 03:23:26.082740: \n",
      "2025-11-17 03:23:26.083730: Epoch 190\n",
      "2025-11-17 03:23:26.083730: Current learning rate: 0.00067\n",
      "2025-11-17 03:57:20.974167: train_loss -0.9515\n",
      "2025-11-17 03:57:20.975163: val_loss -0.8233\n",
      "2025-11-17 03:57:20.975163: Pseudo dice [0.8419]\n",
      "2025-11-17 03:57:20.976694: Epoch time: 2034.89 s\n",
      "2025-11-17 03:57:22.199686: \n",
      "2025-11-17 03:57:22.200679: Epoch 191\n",
      "2025-11-17 03:57:22.200679: Current learning rate: 0.00061\n",
      "2025-11-17 04:31:16.789304: train_loss -0.9516\n",
      "2025-11-17 04:31:16.790310: val_loss -0.8211\n",
      "2025-11-17 04:31:16.791301: Pseudo dice [0.8393]\n",
      "2025-11-17 04:31:16.791301: Epoch time: 2034.59 s\n",
      "2025-11-17 04:31:17.977100: \n",
      "2025-11-17 04:31:17.977100: Epoch 192\n",
      "2025-11-17 04:31:17.978111: Current learning rate: 0.00055\n",
      "2025-11-17 05:05:12.846967: train_loss -0.9516\n",
      "2025-11-17 05:05:12.847960: val_loss -0.8253\n",
      "2025-11-17 05:05:12.847960: Pseudo dice [0.843]\n",
      "2025-11-17 05:05:12.848966: Epoch time: 2034.87 s\n",
      "2025-11-17 05:05:14.433787: \n",
      "2025-11-17 05:05:14.433787: Epoch 193\n",
      "2025-11-17 05:05:14.433787: Current learning rate: 0.00049\n",
      "2025-11-17 05:39:10.420198: train_loss -0.9514\n",
      "2025-11-17 05:39:10.421197: val_loss -0.828\n",
      "2025-11-17 05:39:10.421197: Pseudo dice [0.8457]\n",
      "2025-11-17 05:39:10.422199: Epoch time: 2035.99 s\n",
      "2025-11-17 05:39:11.610860: \n",
      "2025-11-17 05:39:11.611858: Epoch 194\n",
      "2025-11-17 05:39:11.611858: Current learning rate: 0.00043\n",
      "2025-11-17 06:13:08.039904: train_loss -0.9521\n",
      "2025-11-17 06:13:08.039904: val_loss -0.825\n",
      "2025-11-17 06:13:08.041408: Pseudo dice [0.8436]\n",
      "2025-11-17 06:13:08.041408: Epoch time: 2036.43 s\n",
      "2025-11-17 06:13:09.321732: \n",
      "2025-11-17 06:13:09.321732: Epoch 195\n",
      "2025-11-17 06:13:09.323066: Current learning rate: 0.00036\n",
      "2025-11-17 06:47:05.280941: train_loss -0.9528\n",
      "2025-11-17 06:47:05.282137: val_loss -0.8223\n",
      "2025-11-17 06:47:05.283138: Pseudo dice [0.8414]\n",
      "2025-11-17 06:47:05.283138: Epoch time: 2035.96 s\n",
      "2025-11-17 06:47:06.566173: \n",
      "2025-11-17 06:47:06.566173: Epoch 196\n",
      "2025-11-17 06:47:06.566173: Current learning rate: 0.0003\n",
      "2025-11-17 07:21:02.771092: train_loss -0.9521\n",
      "2025-11-17 07:21:02.772094: val_loss -0.8213\n",
      "2025-11-17 07:21:02.773095: Pseudo dice [0.8407]\n",
      "2025-11-17 07:21:02.773095: Epoch time: 2036.21 s\n",
      "2025-11-17 07:21:04.005152: \n",
      "2025-11-17 07:21:04.006170: Epoch 197\n",
      "2025-11-17 07:21:04.006170: Current learning rate: 0.00023\n",
      "2025-11-17 07:55:01.069512: train_loss -0.9525\n",
      "2025-11-17 07:55:01.070521: val_loss -0.8277\n",
      "2025-11-17 07:55:01.070521: Pseudo dice [0.8453]\n",
      "2025-11-17 07:55:01.072049: Epoch time: 2037.07 s\n",
      "2025-11-17 07:55:02.289193: \n",
      "2025-11-17 07:55:02.289193: Epoch 198\n",
      "2025-11-17 07:55:02.290214: Current learning rate: 0.00016\n",
      "2025-11-17 08:28:59.217565: train_loss -0.9521\n",
      "2025-11-17 08:28:59.218564: val_loss -0.8275\n",
      "2025-11-17 08:28:59.218564: Pseudo dice [0.8461]\n",
      "2025-11-17 08:28:59.218564: Epoch time: 2036.93 s\n",
      "2025-11-17 08:29:00.466663: \n",
      "2025-11-17 08:29:00.468171: Epoch 199\n",
      "2025-11-17 08:29:00.468171: Current learning rate: 8e-05\n",
      "2025-11-17 09:02:57.686465: train_loss -0.9535\n",
      "2025-11-17 09:02:57.687470: val_loss -0.8216\n",
      "2025-11-17 09:02:57.687470: Pseudo dice [0.8404]\n",
      "2025-11-17 09:02:57.688473: Epoch time: 2037.22 s\n",
      "2025-11-17 09:02:59.543812: Training done.\n",
      "2025-11-17 09:02:59.677560: Using splits from existing split file: D:\\Capstone\\Experiment 3\\nnUNet_preprocessed\\Dataset123_ISLES22\\splits_final.json\n",
      "2025-11-17 09:02:59.681120: The split file contains 5 splits.\n",
      "2025-11-17 09:02:59.682117: Desired fold for training: 0\n",
      "2025-11-17 09:02:59.682117: This split has 200 training and 50 validation cases.\n",
      "2025-11-17 09:02:59.684123: predicting ISLES22_0010\n",
      "2025-11-17 09:02:59.694650: ISLES22_0010, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:04.639337: predicting ISLES22_0011\n",
      "2025-11-17 09:03:04.645087: ISLES22_0011, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:07.436742: predicting ISLES22_0017\n",
      "2025-11-17 09:03:07.442750: ISLES22_0017, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:11.411203: predicting ISLES22_0019\n",
      "2025-11-17 09:03:11.419250: ISLES22_0019, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:15.744677: predicting ISLES22_0021\n",
      "2025-11-17 09:03:15.750680: ISLES22_0021, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:20.817566: predicting ISLES22_0028\n",
      "2025-11-17 09:03:20.824091: ISLES22_0028, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:24.738279: predicting ISLES22_0031\n",
      "2025-11-17 09:03:24.744285: ISLES22_0031, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:28.818356: predicting ISLES22_0034\n",
      "2025-11-17 09:03:28.824593: ISLES22_0034, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:32.933705: predicting ISLES22_0041\n",
      "2025-11-17 09:03:32.940236: ISLES22_0041, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:37.251129: predicting ISLES22_0048\n",
      "2025-11-17 09:03:37.258787: ISLES22_0048, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:40.641802: predicting ISLES22_0051\n",
      "2025-11-17 09:03:40.647801: ISLES22_0051, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:43.322929: predicting ISLES22_0053\n",
      "2025-11-17 09:03:43.328960: ISLES22_0053, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:45.584387: predicting ISLES22_0055\n",
      "2025-11-17 09:03:45.590933: ISLES22_0055, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:48.391636: predicting ISLES22_0068\n",
      "2025-11-17 09:03:48.398200: ISLES22_0068, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:51.030029: predicting ISLES22_0069\n",
      "2025-11-17 09:03:51.036029: ISLES22_0069, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:53.410616: predicting ISLES22_0072\n",
      "2025-11-17 09:03:53.415623: ISLES22_0072, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:03:55.608592: predicting ISLES22_0074\n",
      "2025-11-17 09:03:55.615083: ISLES22_0074, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:03:57.984128: predicting ISLES22_0086\n",
      "2025-11-17 09:03:57.990647: ISLES22_0086, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:00.267137: predicting ISLES22_0093\n",
      "2025-11-17 09:04:00.274125: ISLES22_0093, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:04:02.585769: predicting ISLES22_0094\n",
      "2025-11-17 09:04:02.590767: ISLES22_0094, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:04.897377: predicting ISLES22_0104\n",
      "2025-11-17 09:04:04.903368: ISLES22_0104, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:07.403022: predicting ISLES22_0105\n",
      "2025-11-17 09:04:07.407056: ISLES22_0105, shape torch.Size([3, 72, 128, 128]), rank 0\n",
      "2025-11-17 09:04:15.854271: predicting ISLES22_0110\n",
      "2025-11-17 09:04:15.860834: ISLES22_0110, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:18.144410: predicting ISLES22_0118\n",
      "2025-11-17 09:04:18.150444: ISLES22_0118, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:20.405742: predicting ISLES22_0121\n",
      "2025-11-17 09:04:20.411737: ISLES22_0121, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:22.724216: predicting ISLES22_0123\n",
      "2025-11-17 09:04:22.730657: ISLES22_0123, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:24.979613: predicting ISLES22_0135\n",
      "2025-11-17 09:04:24.985691: ISLES22_0135, shape torch.Size([3, 74, 112, 112]), rank 0\n",
      "2025-11-17 09:04:27.347486: predicting ISLES22_0137\n",
      "2025-11-17 09:04:27.353507: ISLES22_0137, shape torch.Size([3, 33, 115, 115]), rank 0\n",
      "2025-11-17 09:04:31.288508: predicting ISLES22_0140\n",
      "2025-11-17 09:04:31.292521: ISLES22_0140, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:33.674939: predicting ISLES22_0146\n",
      "2025-11-17 09:04:33.680986: ISLES22_0146, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:36.003238: predicting ISLES22_0148\n",
      "2025-11-17 09:04:36.008737: ISLES22_0148, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:38.387701: predicting ISLES22_0151\n",
      "2025-11-17 09:04:38.395015: ISLES22_0151, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:04:40.660525: predicting ISLES22_0160\n",
      "2025-11-17 09:04:40.665535: ISLES22_0160, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:04:42.935636: predicting ISLES22_0161\n",
      "2025-11-17 09:04:42.942158: ISLES22_0161, shape torch.Size([3, 25, 115, 115]), rank 0\n",
      "2025-11-17 09:04:45.944739: predicting ISLES22_0168\n",
      "2025-11-17 09:04:45.947740: ISLES22_0168, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:04:48.210220: predicting ISLES22_0181\n",
      "2025-11-17 09:04:48.216744: ISLES22_0181, shape torch.Size([3, 76, 112, 112]), rank 0\n",
      "2025-11-17 09:04:50.671913: predicting ISLES22_0182\n",
      "2025-11-17 09:04:50.678464: ISLES22_0182, shape torch.Size([3, 25, 115, 115]), rank 0\n",
      "2025-11-17 09:04:53.703174: predicting ISLES22_0186\n",
      "2025-11-17 09:04:53.707722: ISLES22_0186, shape torch.Size([3, 25, 115, 115]), rank 0\n",
      "2025-11-17 09:04:56.870864: predicting ISLES22_0187\n",
      "2025-11-17 09:04:56.873898: ISLES22_0187, shape torch.Size([3, 25, 115, 115]), rank 0\n",
      "2025-11-17 09:05:00.019725: predicting ISLES22_0188\n",
      "2025-11-17 09:05:00.023245: ISLES22_0188, shape torch.Size([3, 30, 110, 110]), rank 0\n",
      "2025-11-17 09:05:01.071910: predicting ISLES22_0196\n",
      "2025-11-17 09:05:01.075446: ISLES22_0196, shape torch.Size([3, 73, 112, 112]), rank 0\n",
      "2025-11-17 09:05:03.446286: predicting ISLES22_0197\n",
      "2025-11-17 09:05:03.452290: ISLES22_0197, shape torch.Size([3, 25, 115, 115]), rank 0\n",
      "2025-11-17 09:05:06.571162: predicting ISLES22_0201\n",
      "2025-11-17 09:05:06.575682: ISLES22_0201, shape torch.Size([3, 63, 120, 120]), rank 0\n",
      "2025-11-17 09:05:14.204160: predicting ISLES22_0205\n",
      "2025-11-17 09:05:14.208738: ISLES22_0205, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:05:16.572144: predicting ISLES22_0207\n",
      "2025-11-17 09:05:16.579677: ISLES22_0207, shape torch.Size([3, 30, 110, 110]), rank 0\n",
      "2025-11-17 09:05:17.567918: predicting ISLES22_0212\n",
      "2025-11-17 09:05:17.571933: ISLES22_0212, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:05:19.912742: predicting ISLES22_0220\n",
      "2025-11-17 09:05:19.919605: ISLES22_0220, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:05:22.245702: predicting ISLES22_0235\n",
      "2025-11-17 09:05:22.252052: ISLES22_0235, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:05:24.476362: predicting ISLES22_0238\n",
      "2025-11-17 09:05:24.481930: ISLES22_0238, shape torch.Size([3, 30, 110, 110]), rank 0\n",
      "2025-11-17 09:05:25.508785: predicting ISLES22_0247\n",
      "2025-11-17 09:05:25.512313: ISLES22_0247, shape torch.Size([3, 72, 112, 112]), rank 0\n",
      "2025-11-17 09:05:37.781881: Validation complete\n",
      "2025-11-17 09:05:37.781881: Mean Validation Dice:  0.7500859527762844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ankit\\anaconda3\\envs\\nnunet-gpu\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 124 2d 0 --c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISLES22_0010</td>\n",
       "      <td>0.691047</td>\n",
       "      <td>0.527938</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.650831</td>\n",
       "      <td>0.691047</td>\n",
       "      <td>274</td>\n",
       "      <td>98</td>\n",
       "      <td>147</td>\n",
       "      <td>902649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISLES22_0011</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.816295</td>\n",
       "      <td>0.759114</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>1062</td>\n",
       "      <td>239</td>\n",
       "      <td>337</td>\n",
       "      <td>914074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISLES22_0017</td>\n",
       "      <td>0.812573</td>\n",
       "      <td>0.684315</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.937627</td>\n",
       "      <td>0.716952</td>\n",
       "      <td>0.812573</td>\n",
       "      <td>1383</td>\n",
       "      <td>92</td>\n",
       "      <td>546</td>\n",
       "      <td>913691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISLES22_0019</td>\n",
       "      <td>0.875266</td>\n",
       "      <td>0.778198</td>\n",
       "      <td>0.997596</td>\n",
       "      <td>0.862334</td>\n",
       "      <td>0.888591</td>\n",
       "      <td>0.875266</td>\n",
       "      <td>7617</td>\n",
       "      <td>1216</td>\n",
       "      <td>955</td>\n",
       "      <td>893380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISLES22_0021</td>\n",
       "      <td>0.810865</td>\n",
       "      <td>0.681895</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.915389</td>\n",
       "      <td>0.727765</td>\n",
       "      <td>0.810865</td>\n",
       "      <td>1612</td>\n",
       "      <td>149</td>\n",
       "      <td>603</td>\n",
       "      <td>900804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISLES22_0028</td>\n",
       "      <td>0.888124</td>\n",
       "      <td>0.798762</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.888124</td>\n",
       "      <td>774</td>\n",
       "      <td>60</td>\n",
       "      <td>135</td>\n",
       "      <td>902199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISLES22_0031</td>\n",
       "      <td>0.894465</td>\n",
       "      <td>0.809079</td>\n",
       "      <td>0.997364</td>\n",
       "      <td>0.910142</td>\n",
       "      <td>0.879319</td>\n",
       "      <td>0.894465</td>\n",
       "      <td>10230</td>\n",
       "      <td>1010</td>\n",
       "      <td>1404</td>\n",
       "      <td>903068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISLES22_0034</td>\n",
       "      <td>0.746082</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.746082</td>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>915512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISLES22_0041</td>\n",
       "      <td>0.845217</td>\n",
       "      <td>0.731928</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.977867</td>\n",
       "      <td>0.744257</td>\n",
       "      <td>0.845217</td>\n",
       "      <td>486</td>\n",
       "      <td>11</td>\n",
       "      <td>167</td>\n",
       "      <td>915048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISLES22_0048</td>\n",
       "      <td>0.846897</td>\n",
       "      <td>0.734450</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.903529</td>\n",
       "      <td>0.796945</td>\n",
       "      <td>0.846897</td>\n",
       "      <td>5479</td>\n",
       "      <td>585</td>\n",
       "      <td>1396</td>\n",
       "      <td>895708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISLES22_0051</td>\n",
       "      <td>0.764787</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.712821</td>\n",
       "      <td>0.764787</td>\n",
       "      <td>278</td>\n",
       "      <td>59</td>\n",
       "      <td>112</td>\n",
       "      <td>902719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ISLES22_0053</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>915598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ISLES22_0055</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>0.897208</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.990179</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>2924</td>\n",
       "      <td>29</td>\n",
       "      <td>306</td>\n",
       "      <td>912453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ISLES22_0068</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.225597</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>357</td>\n",
       "      <td>902689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ISLES22_0069</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>903142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ISLES22_0072</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.538716</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.801181</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>814</td>\n",
       "      <td>495</td>\n",
       "      <td>202</td>\n",
       "      <td>901657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ISLES22_0074</td>\n",
       "      <td>0.601047</td>\n",
       "      <td>0.429641</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.982877</td>\n",
       "      <td>0.432881</td>\n",
       "      <td>0.601047</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>376</td>\n",
       "      <td>915044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ISLES22_0086</td>\n",
       "      <td>0.949613</td>\n",
       "      <td>0.904060</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.954538</td>\n",
       "      <td>0.944739</td>\n",
       "      <td>0.949613</td>\n",
       "      <td>5522</td>\n",
       "      <td>263</td>\n",
       "      <td>323</td>\n",
       "      <td>909604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ISLES22_0093</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>903112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISLES22_0094</td>\n",
       "      <td>0.786309</td>\n",
       "      <td>0.647866</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.826848</td>\n",
       "      <td>0.749559</td>\n",
       "      <td>0.786309</td>\n",
       "      <td>425</td>\n",
       "      <td>89</td>\n",
       "      <td>142</td>\n",
       "      <td>915056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ISLES22_0104</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>0.839029</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>0.878128</td>\n",
       "      <td>0.949606</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>9158</td>\n",
       "      <td>1271</td>\n",
       "      <td>486</td>\n",
       "      <td>904797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ISLES22_0105</td>\n",
       "      <td>0.839557</td>\n",
       "      <td>0.723480</td>\n",
       "      <td>0.999472</td>\n",
       "      <td>0.740572</td>\n",
       "      <td>0.969084</td>\n",
       "      <td>0.839557</td>\n",
       "      <td>1630</td>\n",
       "      <td>571</td>\n",
       "      <td>52</td>\n",
       "      <td>1177395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ISLES22_0110</td>\n",
       "      <td>0.823702</td>\n",
       "      <td>0.700250</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>0.939665</td>\n",
       "      <td>0.733217</td>\n",
       "      <td>0.823702</td>\n",
       "      <td>841</td>\n",
       "      <td>54</td>\n",
       "      <td>306</td>\n",
       "      <td>914511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ISLES22_0118</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.581454</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>464</td>\n",
       "      <td>2</td>\n",
       "      <td>334</td>\n",
       "      <td>914912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ISLES22_0121</td>\n",
       "      <td>0.928854</td>\n",
       "      <td>0.867159</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.928854</td>\n",
       "      <td>470</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>915170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ISLES22_0123</td>\n",
       "      <td>0.945651</td>\n",
       "      <td>0.896905</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.939894</td>\n",
       "      <td>0.951478</td>\n",
       "      <td>0.945651</td>\n",
       "      <td>11040</td>\n",
       "      <td>706</td>\n",
       "      <td>563</td>\n",
       "      <td>903403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ISLES22_0135</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>108</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>927996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ISLES22_0137</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.418440</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>953418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ISLES22_0140</td>\n",
       "      <td>0.526616</td>\n",
       "      <td>0.357419</td>\n",
       "      <td>0.986938</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.376493</td>\n",
       "      <td>0.526616</td>\n",
       "      <td>6653</td>\n",
       "      <td>943</td>\n",
       "      <td>11018</td>\n",
       "      <td>897098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ISLES22_0146</td>\n",
       "      <td>0.637419</td>\n",
       "      <td>0.467803</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.470118</td>\n",
       "      <td>0.637419</td>\n",
       "      <td>1235</td>\n",
       "      <td>13</td>\n",
       "      <td>1392</td>\n",
       "      <td>913072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ISLES22_0148</td>\n",
       "      <td>0.829752</td>\n",
       "      <td>0.709040</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.880702</td>\n",
       "      <td>0.829752</td>\n",
       "      <td>251</td>\n",
       "      <td>69</td>\n",
       "      <td>34</td>\n",
       "      <td>915358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ISLES22_0151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>915712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ISLES22_0160</td>\n",
       "      <td>0.444156</td>\n",
       "      <td>0.285476</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.308664</td>\n",
       "      <td>0.444156</td>\n",
       "      <td>171</td>\n",
       "      <td>45</td>\n",
       "      <td>383</td>\n",
       "      <td>902569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ISLES22_0161</td>\n",
       "      <td>0.945851</td>\n",
       "      <td>0.897266</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.925799</td>\n",
       "      <td>0.945851</td>\n",
       "      <td>5677</td>\n",
       "      <td>195</td>\n",
       "      <td>455</td>\n",
       "      <td>403273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ISLES22_0168</td>\n",
       "      <td>0.861774</td>\n",
       "      <td>0.757121</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0.828061</td>\n",
       "      <td>0.898349</td>\n",
       "      <td>0.861774</td>\n",
       "      <td>3429</td>\n",
       "      <td>712</td>\n",
       "      <td>388</td>\n",
       "      <td>898639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ISLES22_0181</td>\n",
       "      <td>0.396893</td>\n",
       "      <td>0.247577</td>\n",
       "      <td>0.998208</td>\n",
       "      <td>0.697270</td>\n",
       "      <td>0.277394</td>\n",
       "      <td>0.396893</td>\n",
       "      <td>562</td>\n",
       "      <td>244</td>\n",
       "      <td>1464</td>\n",
       "      <td>951074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ISLES22_0182</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>409495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ISLES22_0186</td>\n",
       "      <td>0.663053</td>\n",
       "      <td>0.495946</td>\n",
       "      <td>0.999089</td>\n",
       "      <td>0.943445</td>\n",
       "      <td>0.511142</td>\n",
       "      <td>0.663053</td>\n",
       "      <td>367</td>\n",
       "      <td>22</td>\n",
       "      <td>351</td>\n",
       "      <td>408860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ISLES22_0187</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>357</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>409139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ISLES22_0188</td>\n",
       "      <td>0.793592</td>\n",
       "      <td>0.657813</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>0.978860</td>\n",
       "      <td>0.667293</td>\n",
       "      <td>0.793592</td>\n",
       "      <td>1065</td>\n",
       "      <td>23</td>\n",
       "      <td>531</td>\n",
       "      <td>1104301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ISLES22_0196</td>\n",
       "      <td>0.900369</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.869359</td>\n",
       "      <td>0.900369</td>\n",
       "      <td>1464</td>\n",
       "      <td>104</td>\n",
       "      <td>220</td>\n",
       "      <td>913924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ISLES22_0197</td>\n",
       "      <td>0.795580</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.795580</td>\n",
       "      <td>288</td>\n",
       "      <td>56</td>\n",
       "      <td>92</td>\n",
       "      <td>409164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ISLES22_0201</td>\n",
       "      <td>0.866513</td>\n",
       "      <td>0.764466</td>\n",
       "      <td>0.993962</td>\n",
       "      <td>0.786283</td>\n",
       "      <td>0.964976</td>\n",
       "      <td>0.866513</td>\n",
       "      <td>18377</td>\n",
       "      <td>4995</td>\n",
       "      <td>667</td>\n",
       "      <td>913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ISLES22_0205</td>\n",
       "      <td>0.841714</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.941477</td>\n",
       "      <td>0.761068</td>\n",
       "      <td>0.841714</td>\n",
       "      <td>3507</td>\n",
       "      <td>218</td>\n",
       "      <td>1101</td>\n",
       "      <td>898342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ISLES22_0207</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>2312</td>\n",
       "      <td>128</td>\n",
       "      <td>408</td>\n",
       "      <td>1103072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ISLES22_0212</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "      <td>903021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ISLES22_0220</td>\n",
       "      <td>0.721951</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.652941</td>\n",
       "      <td>0.721951</td>\n",
       "      <td>444</td>\n",
       "      <td>106</td>\n",
       "      <td>236</td>\n",
       "      <td>902382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ISLES22_0235</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>0.682942</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.904996</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>1105</td>\n",
       "      <td>116</td>\n",
       "      <td>397</td>\n",
       "      <td>901550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ISLES22_0238</td>\n",
       "      <td>0.852109</td>\n",
       "      <td>0.742326</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.808979</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.852109</td>\n",
       "      <td>1838</td>\n",
       "      <td>434</td>\n",
       "      <td>204</td>\n",
       "      <td>1103444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ISLES22_0247</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.771689</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.936052</td>\n",
       "      <td>0.814636</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>1859</td>\n",
       "      <td>127</td>\n",
       "      <td>423</td>\n",
       "      <td>900759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            case      dice       iou  accuracy  precision    recall  f1_score  \\\n",
       "0   ISLES22_0010  0.691047  0.527938  0.999729   0.736559  0.650831  0.691047   \n",
       "1   ISLES22_0011  0.786667  0.648352  0.999371   0.816295  0.759114  0.786667   \n",
       "2   ISLES22_0017  0.812573  0.684315  0.999303   0.937627  0.716952  0.812573   \n",
       "3   ISLES22_0019  0.875266  0.778198  0.997596   0.862334  0.888591  0.875266   \n",
       "4   ISLES22_0021  0.810865  0.681895  0.999167   0.915389  0.727765  0.810865   \n",
       "5   ISLES22_0028  0.888124  0.798762  0.999784   0.928058  0.851485  0.888124   \n",
       "6   ISLES22_0031  0.894465  0.809079  0.997364   0.910142  0.879319  0.894465   \n",
       "7   ISLES22_0034  0.746082  0.595000  0.999912   0.725610  0.767742  0.746082   \n",
       "8   ISLES22_0041  0.845217  0.731928  0.999806   0.977867  0.744257  0.845217   \n",
       "9   ISLES22_0048  0.846897  0.734450  0.997807   0.903529  0.796945  0.846897   \n",
       "10  ISLES22_0051  0.764787  0.619154  0.999811   0.824926  0.712821  0.764787   \n",
       "11  ISLES22_0053  0.824742  0.701754  0.999963   0.769231  0.888889  0.824742   \n",
       "12  ISLES22_0055  0.945819  0.897208  0.999634   0.990179  0.905263  0.945819   \n",
       "13  ISLES22_0068  0.356775  0.217119  0.999585   0.852459  0.225597  0.356775   \n",
       "14  ISLES22_0069  0.631579  0.461538  0.999984   0.571429  0.705882  0.631579   \n",
       "15  ISLES22_0072  0.700215  0.538716  0.999228   0.621849  0.801181  0.700215   \n",
       "16  ISLES22_0074  0.601047  0.429641  0.999584   0.982877  0.432881  0.601047   \n",
       "17  ISLES22_0086  0.949613  0.904060  0.999360   0.954538  0.944739  0.949613   \n",
       "18  ISLES22_0093  0.769231  0.625000  0.999977   0.714286  0.833333  0.769231   \n",
       "19  ISLES22_0094  0.786309  0.647866  0.999748   0.826848  0.749559  0.786309   \n",
       "20  ISLES22_0104  0.912469  0.839029  0.998081   0.878128  0.949606  0.912469   \n",
       "21  ISLES22_0105  0.839557  0.723480  0.999472   0.740572  0.969084  0.839557   \n",
       "22  ISLES22_0110  0.823702  0.700250  0.999607   0.939665  0.733217  0.823702   \n",
       "23  ISLES22_0118  0.734177  0.580000  0.999633   0.995708  0.581454  0.734177   \n",
       "24  ISLES22_0121  0.928854  0.867159  0.999921   0.940000  0.917969  0.928854   \n",
       "25  ISLES22_0123  0.945651  0.896905  0.998614   0.939894  0.951478  0.945651   \n",
       "26  ISLES22_0135  0.586957  0.415385  0.999836   0.580645  0.593407  0.586957   \n",
       "27  ISLES22_0137  0.590000  0.418440  0.999828   0.991597  0.419929  0.590000   \n",
       "28  ISLES22_0140  0.526616  0.357419  0.986938   0.875856  0.376493  0.526616   \n",
       "29  ISLES22_0146  0.637419  0.467803  0.998466   0.989583  0.470118  0.637419   \n",
       "30  ISLES22_0148  0.829752  0.709040  0.999888   0.784375  0.880702  0.829752   \n",
       "31  ISLES22_0151  0.000000  0.000000  1.000000   0.000000  0.000000  0.000000   \n",
       "32  ISLES22_0160  0.444156  0.285476  0.999526   0.791667  0.308664  0.444156   \n",
       "33  ISLES22_0161  0.945851  0.897266  0.998413   0.966792  0.925799  0.945851   \n",
       "34  ISLES22_0168  0.861774  0.757121  0.998782   0.828061  0.898349  0.861774   \n",
       "35  ISLES22_0181  0.396893  0.247577  0.998208   0.697270  0.277394  0.396893   \n",
       "36  ISLES22_0182  0.306452  0.180952  0.999790   1.000000  0.180952  0.306452   \n",
       "37  ISLES22_0186  0.663053  0.495946  0.999089   0.943445  0.511142  0.663053   \n",
       "38  ISLES22_0187  0.872861  0.774403  0.999746   0.852029  0.894737  0.872861   \n",
       "39  ISLES22_0188  0.793592  0.657813  0.999499   0.978860  0.667293  0.793592   \n",
       "40  ISLES22_0196  0.900369  0.818792  0.999646   0.933673  0.869359  0.900369   \n",
       "41  ISLES22_0197  0.795580  0.660550  0.999639   0.837209  0.757895  0.795580   \n",
       "42  ISLES22_0201  0.866513  0.764466  0.993962   0.786283  0.964976  0.866513   \n",
       "43  ISLES22_0205  0.841714  0.726689  0.998540   0.941477  0.761068  0.841714   \n",
       "44  ISLES22_0207  0.896124  0.811798  0.999515   0.947541  0.850000  0.896124   \n",
       "45  ISLES22_0212  0.338983  0.204082  0.999870   0.769231  0.217391  0.338983   \n",
       "46  ISLES22_0220  0.721951  0.564885  0.999621   0.807273  0.652941  0.721951   \n",
       "47  ISLES22_0235  0.811605  0.682942  0.999432   0.904996  0.735686  0.811605   \n",
       "48  ISLES22_0238  0.852109  0.742326  0.999423   0.808979  0.900098  0.852109   \n",
       "49  ISLES22_0247  0.871134  0.771689  0.999391   0.936052  0.814636  0.871134   \n",
       "\n",
       "       TP    FP     FN       TN  \n",
       "0     274    98    147   902649  \n",
       "1    1062   239    337   914074  \n",
       "2    1383    92    546   913691  \n",
       "3    7617  1216    955   893380  \n",
       "4    1612   149    603   900804  \n",
       "5     774    60    135   902199  \n",
       "6   10230  1010   1404   903068  \n",
       "7     119    45     36   915512  \n",
       "8     486    11    167   915048  \n",
       "9    5479   585   1396   895708  \n",
       "10    278    59    112   902719  \n",
       "11     80    24     10   915598  \n",
       "12   2924    29    306   912453  \n",
       "13    104    18    357   902689  \n",
       "14     12     9      5   903142  \n",
       "15    814   495    202   901657  \n",
       "16    287     5    376   915044  \n",
       "17   5522   263    323   909604  \n",
       "18     35    14      7   903112  \n",
       "19    425    89    142   915056  \n",
       "20   9158  1271    486   904797  \n",
       "21   1630   571     52  1177395  \n",
       "22    841    54    306   914511  \n",
       "23    464     2    334   914912  \n",
       "24    470    30     42   915170  \n",
       "25  11040   706    563   903403  \n",
       "26    108    78     74   927996  \n",
       "27    118     1    163   953418  \n",
       "28   6653   943  11018   897098  \n",
       "29   1235    13   1392   913072  \n",
       "30    251    69     34   915358  \n",
       "31      0     0      0   915712  \n",
       "32    171    45    383   902569  \n",
       "33   5677   195    455   403273  \n",
       "34   3429   712    388   898639  \n",
       "35    562   244   1464   951074  \n",
       "36     19     0     86   409495  \n",
       "37    367    22    351   408860  \n",
       "38    357    62     42   409139  \n",
       "39   1065    23    531  1104301  \n",
       "40   1464   104    220   913924  \n",
       "41    288    56     92   409164  \n",
       "42  18377  4995    667   913653  \n",
       "43   3507   218   1101   898342  \n",
       "44   2312   128    408  1103072  \n",
       "45     30     9    108   903021  \n",
       "46    444   106    236   902382  \n",
       "47   1105   116    397   901550  \n",
       "48   1838   434    204  1103444  \n",
       "49   1859   127    423   900759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: nnunet_validation_metrics.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAHDCAYAAAAA+eLHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGyElEQVR4nO3dB3gUZffw4TNBSWgJhN5FQKT3EqQXEVDBhqK+FCmCgCDYYkEBKUpXuojgi0iT4h8RRKSoFAFBioKCQICXptKV0Pa7zsO3626yCRvckB3md3uNYWdnp2yZM+dpY7lcLpcAAICQE5bWOwAAAPwjSAMAEKII0gAAhCiCNAAAIYogDQBAiCJIAwAQogjSAACEKII0AAAhiiANAECIIkg71K+//ip33323REVFiWVZsmDBgqCuf9++fWa9U6dODep67axevXpmCqYDBw5IRESEfPfdd0FdLwK3cuVK813Xv26PPfaYtGrVKk33CzcHgnQa2rNnjzz99NNy++23mxNtZGSk3HXXXTJ69Gj5+++/U3Xbbdu2lW3btsnAgQPlv//9r1SpUkVuFu3atTMnTX0//b2PeoGiz+s0bNiwFK//f//7n7z55puyZcsWSWv9+/eX6tWrm++NPxoo9DhfeuklcbpBgwYF/WI0Kfp+f/rpp/Ljjz/ekO3hJqZjd+PGW7RokStDhgyurFmzup599lnXpEmTXGPGjHE99thjrltvvdXVqVOnVNv2X3/9peO1u1599dVU28aVK1dcf//9t+vSpUuuG61t27auW265xZUuXTrXrFmzEj3/xhtvuCIiIsx7MHTo0BSvf8OGDea1H374YYpeFx8fb6ZgOXbsmPmuzJgxw+/zp06dMsd52223uQoWLGg+EyfLlCmT+W4E24oVK8z3Qf96q1atmus///lP0LcHZyGTTgN79+41xWGFCxeWn376yWTOnTp1km7dusknn3xi5pUuXTrVtn/8+HHzN2vWrKm2Dc3etHQgXbp0khbCw8OlYcOG5v1MaMaMGdK8efMbti9//fWX+Zs+fXozBcv06dPllltukfvuu8/v85rJXb58WaZMmWKKxVevXi1p5dy5c+I0Wooxb948OXv2bFrvCuwsra8SnKhLly7myvu7774LaPmLFy+6+vfv77r99ttd6dOndxUuXNgVGxvrOn/+vM9yOr958+aub775xlW1alVXeHi4q0iRIq5p06b5ZJG6be9JX6c0y3D/25v7Nd6+/PJL11133eWKiooyGcodd9xh9slt7969frPN5cuXu2rVquXKmDGjee3999/v+umnn/xu79dffzX7pMtFRka62rVr5zp37tw13y99je7T1KlTzXtw4sQJz3Pff/+9Wfenn36aKJP+448/XH369HGVKVPGvD5Lliyue+65x7Vly5ZEWVPCyX2cdevWdZUuXdq1ceNGV+3atU1pSc+ePT3P6eTWpk0bs38Jj//uu+82JSyHDh1K9jjr1KnjqlevXpLPN2zY0NWsWTPz75IlSyZZOvPjjz+adWnWnT9/fteAAQNcU6ZMMceln6Pb5cuXzWeTN29ec1y67R07dpjvjHeGqu+FvnblypWurl27unLmzGmOx23x4sWe70DmzJnNPm7fvj3Rfs2ePdvst75H+p7OmzfP73dUP8OYmBhXdHS0OYZKlSq55syZ47OMv8/Me58PHjzoat++vStXrlzmN1aqVCnXBx98kGifDhw44GrRooXZdz2uXr16uZYsWeI3k9b3VefrfgPXiyCdBvREqAE3UHoy0R/7ww8/7Bo7dqw5uevjli1b+iynJ68SJUq4cufO7XrllVdM8bmesCzL8pwE9cQxcuRI8/rWrVu7/vvf/7rmz5+foiCt69ITWZUqVVyjR492TZgwwfX888+bE31yQXrZsmWmGFoD+jvvvOPq16+fK0eOHK5s2bL5BAP39ipWrOh68MEHXePGjXN17NjRzHvxxRcDer80yJ4+fdqctL1PtnpSvfPOOz375x2ktRi7aNGirpdfftk1ceJEc2Gkn5VeJLgD5pEjR8x8fW3nzp3N+6fTnj17zPMahPPkyWNO4D169DDrWbBggd8grRcPBQoUMBdU7moBfS913brO5Fy4cMEEyt69e/t9Xvc3LCzMsx7dZ32fExa3a3DS4JY9e3bzeQwbNsy8P+XLl08UpPW913n33Xef+W5p0Nf918/QX5DWQKfH+95777mGDBlinvvoo4/M91EvfnT+22+/bYrjNYh7b0urg3S5cuXKuUaMGOF6/fXXzf7rBVTC76juwzPPPGP2SZfVYmbdvq7DTd8HDfZ64eT+zNasWeP5THUdWiWg79P48ePNxaOuQ38r3tVE+t3V75S+F6NGjXJVrlzZ7KO/IK0X1/oZ6YUfcL0I0jeY1hPqD1qvxgOhWZwur0HKmwZFnf/111975unJS+etXr3ap95ST07eJwp/ASolQdod5I8fP57kfvsL0hUqVDCZimasbnrRoMFELzwSbu+pp57yWecDDzxggkmgQVrphY1mlO5MUAOoBiN/74GWTOgyCY9D3z89eQdSJ61BSZ/TYOvvOe8grZYuXWqWf+utt1y//fabySwTXnz5s3v3bvM6DXT+aLDVAKEXKuqXX34xy7svyNz0QkKD4ebNmz3z9PPRwO0dpDWQ6QVWwn178803E2Wl7iCt2bJ3m4QzZ86YYJwwo9d164WQ9/yyZcuawKmvcdPM3Lvkxzt4JryA0WDeoEGDgOqkO3ToYEoHfv/9d5/52j5E98u9fg3Kun3N8N20ZKdYsWJ+g7TSoN60adNE84FAUSd9g50+fdr8zZIlS0DLL1682Pzt3bu3z/w+ffqYv59//rnP/FKlSknt2rU9j3PmzCklSpSQ3377TYLFXZe9cOFCuXLlSkCvOXz4sGkNrS2vo6OjPfPLlSsnjRs39hynty5duvg81uP6448/PO9hIB5//HHTNebIkSPy9ddfm786L6l67LCwqz8JrcvVbWXOnNm8fz/88EPA29T1tG/fPqBltRuctvDXVtoPPvigqcefOHHiNV+n+6ayZcvm9/mPP/7Y1Lu7v2fFixeXypUrm/nelixZIjExMVKhQgXPPP18nnjiCZ/lli9fLpcuXZJnnnnGZ36PHj2S3EdtZ+HdJmHZsmVy8uRJad26tfz++++eSZfRFuorVqzwtJ7Xngdt2rQx779b3bp1pWzZsom2kyFDBs+/T5w4IadOnTLflUA+M01UtO5e6/X139771aRJE7Mu93r0O5o3b155+OGHPa/PmDGjdO7cOcn16+ej6wKuF0H6BtNuQerMmTMBLb9//34TOIoVK+YzP0+ePCZY6vPeChUq5PdEoSevYHn00UdNl5+OHTtK7ty5TSO42bNnJxuw3fupAS+hkiVLmhNZwsZFCY/FHZBScizNmjUzgWrWrFkmQFWtWjXRe+mm+z9y5EgT0DTQ5siRw1zkbN261ZysA5U/f/4UNRDTbmAaGPUi5t1335VcuXIF/Nqr1a2+fv75Z9m8ebP5jHbv3u2ZtI/2okWLfC5y9HPx934knOf+/BLO1/1O6kKhSJEiibq+qQYNGpj31Xv68ssv5dixY8luK6l5ekw1atQwFzi6P7q+8ePHB/SZaSNKvXCYNGlSon1yX2h575duXxtFevP3nfb+fBIuj8CtXr3aXEDly5fvusZz0K6S7u6W3lOmTJnELm5J6x1wYpDWL9z27dtT9LpAf+hJtab2dzIPdBuaVSbMXPTHo5mPZvKajWkQ1JOvnmyD1aL73xyLmwZbzVCnTZtmShP0R5tcP9rXX39dnnrqKRkwYIA54esFUq9evQIuMUiY2QVCA6o7EGgGqZnmtWTPnj3JCxZt9a2ee+45MyWkmWOgmf6/kfB9cL+H2i9fLzIT0pbqKfXNN9/I/fffL3Xq1JFx48aZTPfWW2+VDz/80LTivxb3Pj355JNm7AB/tLTneunnoxd9uD7nzp2T8uXLm9+k/o5T6vnnn09UIqe9PvRi3S4I0mng3nvvNVfua9euNUWNydFuWnoi0SxEM063o0ePmgxAnw8WzYh0nQklzNaVBi/9sus0YsQIE+BeffVVE7gbNWrk9zjUrl27Ej23c+dOk7Wm1tWtFm9rNyTdZ836kzJ37lypX7++fPDBBz7z9T3R/XMLZmakJyENmFpNUbNmTXnnnXfkgQceuOZJREsZNAhqd76EFzAanPQ4EhZNK7340BIFd5DWz0Wz7IQSznN/fjrfO0PWYvdASzaKFi1q/mpJgb/viL9tXWu/9IJDM+ilS5eaCzI3DdIJ+fvcNGPWkha9EE1un9z7pRfXCbNjf99ppdUD2vVNLyJwfZo2bWqmpMTHx5vzjna11N9pmTJl5O233/aM7KfVJd5VJjq4jHZxnTBhgtgFxd1p4MUXXzQBSYuLNdj6G4lM+067i2vVqFGjfJbRwKiC2d9XT6JaRKjFu951yfPnz/dZ7s8//0z0Wnedpv5o/NEMR5fRjNb7QkBPepp9u48zNWjA0uA0ZswYvxmcd+aeMEufM2eOHDp0yGee+2LC3wXN9YxMFRcXZ94X/Uxvu+02k9El9T66abaoo8Rt3LjRZ74OD6pDsmoQ1rrThJNWVeiFlNb7Kq131YtF79HT9PNNWHetF2Oa6Woxsjd9TwOl29KSJL2gu3jxYpL997WkSU+2H330kU8f41WrVpmShoSfmQZM79IePX5/xaL6uSX8zPT1Dz30kAn2/kq33Puk9Duq75tezHn3gdcLbn80GJw/f95cfCF1dO/e3Xx/Z86cac5bjzzyiNxzzz2eqpWEJk+eLHfccYdPu52QF3ATMwTVwoULTVcO7Vai/Wjff/99073qiSeeMN2btHtPwi5YrVq1Msu4H/vrgqX9pK/Vqjip1t3aulVbwGr3MG3JOmjQINMtRbtxeX9VdH+1e9Rrr71m9nvgwIGmq5K2xj158uQ1u2BpFx/dtraY1q5K+h5oy+aErbsTth53txr27qpzrdbdSfH3HvTt29fM0/7YOgKctnzWVs76fni/f9p6WFspa3e3yZMnuz755BPP/rv7SfuT8HPQPuPaslpbSLtpy3xt7f7CCy+4rkVbcGvLc+0x4N0HX0da825B723btm3mGIcPH24ex8XFmWPRblTeXbC0Jb4ut2/fPs9rtYeAuwuWfg/1O6rfD32tvmcJPydtBZ/Qxx9/bI5PW19ri3btoqYj3+n2unXr5lnus88+83TB0t4E+tnoZ6Gv0y5b3u+hbku7VmnXKT0G7UHg7hblTftj6/dCj10/s3Xr1nlal+tvR/s+63db92nw4MGuRx55xHw3E7bk1t/tSy+9dM0uWPpe6jrdLezx70iC3gn79+833/WE4wlobw7vMRvcdARE/Ty125+dEKTTkHaL0W4netLRwKyDZ+gAIdqtxnugEu1vqScfHZhEh4HUE2Nyg5lcb5B2D1KiJ0LdHw1C06dPT9QFS0+M2oUsX758Zjn9q32u9XgSbiNhN6WvvvrKHKN2D9IBSvSEn9RgJjc6SOv7qYHIPViH7ufatWv9dp3SiyztB6wXHf4GM/HHez164tbPSy+A9PP19txzz5lApttOztGjR8323X2h9eJBu6hpwEqOfo/0IstNu1/pazTg64WWBqh3333XHJcGMDftTqX9lbUbm74/2sXp559/NtvUi4NAgrTSYNakSRPTvUkDnvZN1yCvA8B4mzlzprlg0P3S76QG7oceesjM86b94IsXL26W0+d0+/4G4Nm5c6fpy6/7nrDbmL6XepGgvy39jekx6sleL9a8aWDQPtQafPXiRIN6UoOZVK9e3fXkk08m+1ng+oP0okWLzDz9rXtP+pvQhCYhHT5Xn/P+TtuBpf9L62wewPXp0KGD/PLLL6YBVTBpYzntCqbFzck1BNTiY23L8NZbb5m6wdSmVSZaj6zduUKZVh9UqlTJdN/y7t6G62dZlql6a9mypXmsjVW1q+COHTsSfUe1Hjph1ZZW2Wh1S8Lqu1BHwzHAxt544w1Tx6Z10UndCeta9E5h3i2xtTGYtsCuVauWz8kv4XLebSWCfQtOrbPWk7J3i2/t764Nf/SCINQNGTLEtAEgQKeeihUrmrYI2jPiWnXM2sBS22J89tlnYjcEacDGtJW3Nk76N7SHgQZZ7T2gDRm1dbv2pdbuaN40c9H7g2sDKs1Uvv32W9OqVgdkud4LhKRoYz1tba1do7QhmfYA0Ba5mh0l7FITirQhE/69s2fP+rTo12CrpRTaPVIvTjWT1kFvhg8fboK2NvTTgXe025x3o1rt3aGNV5NrKR6y0rq8HUDa0vYNWqerdbVa16rDeWojv4Q2bdpk6mm1DlrrbbX+WutkvYfuDBZtgKj1itogUds9aIMfHeJVh0OFc6xI4oY27vYE2g5DGxVqux79Tmp7Eh0+eOvWrZ516FC/+l3V+xnYEXXSAACEKPpJAwAQogjSAACEKII0AAAhKmRad2eo2D2tdwFIdSc2BD6MJmBXEbfYI1b8vTn0f49k0gAAhKiQyaQBALgmy1m5JUEaAGAfVvBuFWsHzrokAQDARsikAQD2YTkrtyRIAwDsw6K4GwAAhAAyaQCAfVjOyi0J0gAA+7Ao7gYAACGATBoAYB+Ws3JLgjQAwD4sirsBAEAIIJMGANiH5azckiANALAPi+JuAAAQAsikAQD2YTkrtyRIAwDsw6K4GwAAhAAyaQCAfVjOyi0J0gAA+7CcFaSddbQAANgImTQAwD7CnNVwjCANALAPy1kFwM46WgAAbIRMGgBgHxbF3QAAhCbLWQXAzjpaAABshCANALBXcbcVpOlfGDJkiFiWJb169Up2uTlz5sidd94pERERUrZsWVm8eHGKtkOQBgDYq7jbCtJ0nTZs2CATJ06UcuXKJbvcmjVrpHXr1tKhQwfZvHmztGzZ0kzbt28PeFsEaQAAAnT27Fl54okn5P3335ds2bIlu+zo0aPlnnvukRdeeEFKliwpAwYMkEqVKsmYMWMC3RxBGgBgI1baFnd369ZNmjdvLo0aNbrmsmvXrk20XJMmTcz8QNG6GwDgyNbd8fHxZvIWHh5uJn9mzpwpP/zwgynuDsSRI0ckd+7cPvP0sc4PFJk0AMCRBg8eLFFRUT6TzvPnwIED0rNnT/n4449NI7AbhUwaAODIwUxiY2Old+/ePvOSyqI3bdokx44dM3XKbpcvX5bVq1ebOmbNyNOlS+fzmjx58sjRo0d95uljnR8ogjQAwJHF3eHJFG0n1LBhQ9m2bZvPvPbt25vuVS+99FKiAK1iYmJk+fLlPt20li1bZuYHiiANAMA1ZMmSRcqUKeMzL1OmTJI9e3bP/DZt2kj+/Pk9ReZaPF63bl0ZPny4aWymddobN26USZMmSaCokwYA2IcVGoOZ+BMXFyeHDx/2PK5Zs6bMmDHDBOXy5cvL3LlzZcGCBYmCfbKH63K5XBICMlTsnta7AKS6ExsC7x8J2FVEKpbRZrg3eL+hvxeFftwhkwYAIERRJw0AsA/LWbklQRoAYB+Ws+4n7axLEgAAbIRMGgBgH5azckuCNADAPiyKuwEAQAggkwYA2IflrNySIA0AsA+L4m4AABACyKQBALZhOSyTJkgDAGzDcliQprgbAIAQRSYNALAPSxyFIA0AsA2L4m4AABAKyKQBALZhOSyTJkgDAGzDcliQprgbAIAQRSYNALANy2GZNEEaAGAfljgKxd0AAIQoMmkAgG1YFHcDABCaLIcFaYq7AQAIUWTSAADbsByWSROkAQC2YTksSFPcDQBAiCKTBgDYhyWOQpAGANiGRXE3AAAIBWTSAADbsByWSROkAQC2YTksSFPcDQDANYwfP17KlSsnkZGRZoqJiZEvvvgiyeWnTp1qLii8p4iICEkpMmkAgH1YabPZAgUKyJAhQ6R48eLicrlk2rRp0qJFC9m8ebOULl3a72s0mO/atetflQIQpAEAtmGlUXH3fffd5/N44MCBJrtet25dkkFa9zVPnjz/arsUdwMAkAKXL1+WmTNnyrlz50yxd1LOnj0rhQsXloIFC5qse8eOHZJSZNIAAEdm0vHx8WbyFh4ebiZ/tm3bZoLy+fPnJXPmzDJ//nwpVaqU32VLlCghU6ZMMfXYp06dkmHDhknNmjVNoNai80CRSQMAbMNK0Bjr30yDBw+WqKgon0nnJUUD75YtW2T9+vXStWtXadu2rfz0009+l9Vg3qZNG6lQoYLUrVtX5s2bJzlz5pSJEyem7HhdWgMeAjJU7J7WuwCkuhMbxqT1LgCpLiIVy2jzdv40aOva9969KcqkE2rUqJEULVo04MD7yCOPyC233CKffPJJwPtIcTcAwJHF3eEpCMj+XLlyJVGQT64eW4vLmzVrlqJtEKQBAPZhpc1mY2NjpWnTplKoUCE5c+aMzJgxQ1auXClLly41z2vRdv78+T3F5f3795caNWpIsWLF5OTJkzJ06FDZv3+/dOzYMUXbJUgDAHANx44dM4H48OHDpu5aG4RpgG7cuLF5Pi4uTsLC/mnmdeLECenUqZMcOXJEsmXLJpUrV5Y1a9Yk2dAsKHXSWkE+ZswYWbt2rdmw0j5gWkHevXv3FG/cG3XScALqpOEEqVknnb/r/KCt69D4ByTUBfxW6vBnLVu2lEqVKpn+Xrlz5zbzjx49KsuWLTPzFy5cKE2aNEnN/QUAOJjlsLG7A86ky5cvb4KzlrP78+abb5om5lu3br2uHSGThhOQScMJUjOTLvDMgqCt6+C4lhLqAu4n/csvv8gTTzyR5POtW7eWX3/9NVj7BQBAqvaTtoOAg/Rtt90mn3/+eZLP63M6/BkAAAiOgAsltJj78ccfN03OtQO3d5308uXLZcmSJaZJOgAAqcYSRwk4SOtIKdoH7N1335Xhw4cnat2twTu5gcYBAPi3LJsUUwdLiqr3dXBwnQAAQOpjMJM09nz7xjLg2RYy5uMV8sKwq2PSvvfqY9KgegnJmzNKzv4dL+t+3CuvjV4ov+w76nld5VKFzOsqlioo2j5/4/b98uroBbLtl0Pm+dqVi0uPJ+tLldKFJTJzhOyOOy6jpn0lM7/Y6LP9qMwZ5M3u90mLBuUlOiqjxB0+IS8MmytLv706aPzOz/tJ4XzZE+33hFmr5bkhs82/n3rwLnm0aRWpcGcBicycQfLUfkFOnf3bZ/lskRllxEuPSLM6ZeSKyyULlm+R59+ZK+f+vpAK7yrsatPGDTJ1ygfy80/b5fjx4zLy3bHSoGEjz/Ovv/KyfLbQt59szbtqyfhJH3ge79u3V0YOe0e2bP5BLl68KMXvKCHdevSUatVrJNreyZMn5JEHW8ixo0flm7UbJDIyMtEym3/YJB3a/UeKFSsus+ctDPoxI2UsMmncKBpoOzx0l2z95aDP/M0/H5CZX2yQA4dPmMD5apfmsmhcN7nz3jfkyhWXZMqQXhaO7Safr9omPQfPklvShcnrXZvLZ2O7SfGmr8mlS1ekRvkisv3XQzJi6jI5+scZaVa7jEwe0EZOnT0vX3yz3Wzn1lvSyecTusuxP8/IEy98IIeOnZRC+aLl1Jl/AmytJ4dKurB/fhSliuWTxRN6yLxlmz3zMkbcKsvW/GQmvXDw58NBbSVPjii5t+sYs92J/Z6Usa8/Lu1emZoK7yzs6u+//zJ3Gmr54EPSu6f/bpl31aot/d/6505F6dOn93m+xzNdTCPW96dMk/CICPn4o2nSo1sX+fyLZZIjZ06fZd98/VW5444SJkj7c/r0aXntlZekWvUY+fOP34NyjPh3LII0bgQNtB8OaifPDPhEXu54j89zU+Z95/l33OE/pd/Y/5MNs18xGe3eg79LiSJ5JHvWTDJg/CI5ePSkWW7gxC9k45xXpFDeaPntwO8ydMqXPusc+8lKaRhzp8mY3UG6bcsYk+HWazfcBHb39rz9fuKsz+Pn25eRPXHH5ZtN/3S3GzNjpSd796dEkdzS5K7SctcT78gPP8WZeb3fniML3usqsSPny+Hjp67jHcTNqFbtumZKjgblhMHW7cSJPyVu/z7pN2Cg3FHiTjOvZ+8+MmvmDNm9+1ef182eOcOMwdy5yzPy7Ter/a7vrf5vSNNm90q6dOlkxfKv/tWxAdeD+0mnkVGxj8qSb7bLivW7kl0uY0R6aXN/DROcDx45YeZpsbcGz7Yta5qsNCL8VmnXMkZ+/u2w7P+fb5BNWLR94vRfnsfN65aV9Vv3yqiXH5V9Xw0yQf6Fp+6WMK/M2Ztu67FmVWXawrUpOtbq5YqY7boDtPp6/S5TKlC1DN32kDIbN3wv9WrHyP3Nm5ggqkXWblmzZpPbihSR/1u4QP766y+5dOmSzJ09S6KzZ5dSpUp7ltuze7dMHD9O3hr0ts94y94WzP9UDh44IF2eYaClUGI5rJ90wJl0gwYNzIhiWbNmTd09coBHmlSWCncWlFpPvpPkMp0fqS0De7WUzBnDZdfeI9K86xi5eOmyee7sX/HSpNNomT2is8R2upqF7447Jvd3GyuXL1/NiBN6qHFFqVy6kHR/65/7mBbJn13qVb3DFK0/0GO8FC2Y01w8aDAeNOmLROu4v345yZolg0z/v/UpOt7c2SPl+J9nfObpfv55+i/JnSNxHSCQlJq1akvDRo0lf4ECcuDAAXlv1Ah55ulO8t8Zs0y2qyfeSZOnSq9nn5Ga1SqZABwdHS3jJk6WyKgos44LFy7Iyy/0lueef0Hy5ssnBw8eSLSd/fv3yeiRw+XDjz429/9FCLHEUQL+9mkXK/1yB4PefzPhPThdVy6LFZZObnYFcmeVoS88ZOpm4y9cSnI5DZzL1++UPDkipVebRjL97aekQfsR5jWaOU944wlZ++Nv0jb2Q0mXLkx6tWko897tauqQz8df9FlXnSrFTR2wFq3//NvVrnNKT2AaPLsN+MRktVoXni9XVrMuf0FaM/el3/1E8TTSTNNmzT3/1gZhWp/c/J5GJruuXiNGdJTjQW/1k+jo7CbARkREyLy5c+TZbl1kxqy5kjNnLhN8ixQtKvfe1yLJ+/7GvtBHunbrIbfdVuQGHh2QWJpcIur9Nvv16+czL13uqnJr3mpys6tYspDJLNfOeMkz75Zb0kmtSkWly6N1JKp6LxMwT589byat//1+6z45vPodU588e8km05JaG3jVbTvcnJRU29ipZpn76pWTOUs3edZdq3Ix+XR0F3lx2DyZseh7n3058vspk53r9tx27j1iWpVrNu3O3FWhvNlMi/PHnn8/xcd89I/TkjM6i888vbCIjswoR38/neL1AW4FChY0twGMi9tvgvT369fJ6lUrTUvtzJkzm2Ve7Vta1q1dI58tWCAdOnWWDevXya+//iKVvrx6H2D3b6herRrSsXMXebJNO9mxY7vs3PmzDBk4wDx35coVs1ylcqVMS3LdFtKGZZNi6jQJ0nqrSvcgJknRe2wGcvPs3r17+8zLVfufoHUzW/H9Lqn88ECfeZP6PSm79h6V4VOX+QRMN1N/Ipakv/UWTz21Lud9bxTt1qQPw7y+wNqQa967XUz3Le/GaG5rt/xmAr6u372u4oVymUzZO0Cr/9wfY1qBf/HNjhQfs9Z7awO1iiULmmxdaTG71n1v2L4/xesD3I4eOSInT56UnDmuNgj7+++rPRO8fwfKCtPv+NWqoOGj3pPz8ec9z+3Yvk3eeO0Vk3kXKFjIBPe5C/7P5/WzP5kh33+/ToaNfFfy5y9wA44MSbEI0klr2LChT2Bwc5/k9a8WFV1LeHi4mXzW4YCibnd98k97DvvM077Cf546Z+bflj+7PNyksixf+7NpHJY/d1bp0/5u+Tv+oiz99mqAXL5upwzq1VJGxbaS8TNXmRPS8+3vlkuXL8uqjb94irg1QI+dsVIWLN8subNfzWQvXLzsaTz2/pxvTPY+/MWHZdwnq6RYoZzyQoe7zb+96efapkUN+XjRer913rpuLR0oWiiHeVymeD45c+68HDhywmxLL0CWfrfDdLl6duBMk6WPfLmVzFn6A0Xn8PHXuXMSF/dPA8NDBw/Kzp9/lqioKDNNGD9GGjVuItlz5DCNukYOHyoFCxU2ddWqfIUKpq/za6+8LE937SbhEeEyb+5sOXTwkNSuU88sU7BQIZ9tnjxxteFZkduLevpJFy9+h88y2vAsPH14ovlASAXp9evXS84kuj4gOLTO+a6KRaX74/VM9nnsjzPy7Q+7pX674XL8/3eH0tbdD/WcKK8+3VRWTutjsuofdx6UFt3GyZH/X3z85H3VJVOGcHmxQxMzua3e+KtpdKa0+9b93cbJO30elA2zY+V/x06aoK4ZvTct5tauXdMWrPO7zx0fri2vdWnmefzVlOfM3059/+tpZNb+lWkmMC+e2MPsrw5m0uedOUF//2BvWszcsX0bz+Nh71ztD31/iwfk1b5vyi+7fpHPFi6QM6fPSK5cuSSm5l1moBJ3X+ls2a42Entv9Cjp9FRbuXTpohQtVlxGjxkrJe682iUL9mY5K5EO/H7S2shIi7r1h5EauJ80nID7ScMJUvN+0sVfWBK0df061HeMilBEP2kAAEJUwNc7devWTTT8HgAAN5LlsOLugIP04sWLzX2j7733Xk8Lbe++zjqQwIABA0y/RAAAUoPlsCgdcJCeNm2afP75554gPWbMGCldurRkyJDBPN65c6fky5dPnnvuaqMhAABwg+qkp0+fLp07d/aZN2PGDFmxYoWZhg4dKrNnX711IQAAqcGygjfdVEF6z549UrZsWc9jLdb2Hpi+WrVqZrATAABSS1iYFbTppiru1lF9vOug9Ybs3nTYvITjcQMAgBuQSRcoUEC2b796H2J/tm7dapYBACC1WBR3+9esWTPp27evnD//z5i3bjpert4wo3nzf+5QAwBAsFncT9q/V155xTQMK1GihHTv3l3uuOPqGLa7du0yLb315uq6DAAAuMFBOnfu3LJmzRrp2rWrvPzyy54bbejVSOPGjWXcuHFmGQAAUotljwQ4aFI0wmqRIkVkyZIl8ueff8ru3bvNvGLFikl0dHRq7R8AAB52KaYOlusaBl2Dsna5AgAAqScV71UCAEBwWWTSAACEJstZMZpbVQIAcC3jx4+XcuXKSWRkpJliYmLkiy++SPY1c+bMkTvvvNOM0KkjduqNqlKKIA0AsA0rjfpJ62BdQ4YMkU2bNsnGjRulQYMG0qJFC9mxY4ff5bU3VOvWraVDhw6yefNmadmypZmSGxTM7/G63H2p0liGit3TeheAVHdiw5i03gUg1UWkYkVqpf5fB21dP/Rt8K9er42o9eZSGogTevTRR+XcuXOyaNEiz7waNWpIhQoVZMKECQFvg0waAIAUuHz5ssycOdMEYS329mft2rXSqFEjn3lNmjQx81OChmMAAEe27o6Pj090Y6jw8HAz+bNt2zYTlHV47MyZM8v8+fOlVKlSfpc9cuRIogG+9LHOTwkyaQCAI2+wMXjwYImKivKZdF5SdFjsLVu2yPr1683om23btk31WzSTSQMAHCk2NlZ69+7tMy+pLFqlT5/ejLKpKleuLBs2bJDRo0fLxIkTEy2bJ08eOXr0qM88fazzU4JMGgDgyNbd4eHhni5V7im5IJ3QlStXEhWXu2mx+PLly33mLVu2LMk67KSQSQMAbMOy0i7rbtq0qRQqVEjOnDkjM2bMkJUrV8rSpUvN823atJH8+fN7ist79uwpdevWleHDh5vbOGtDM+26NWnSpBRtlyANAMA1HDt2zATiw4cPm7prHdhEA7TeBVLFxcVJWNg/hdM1a9Y0gfy1114zt3EuXry4LFiwQMqUKSMpQT9p4AainzScIDX7SVcfvCpo61ofW1dCHZk0AMA2LMbuBgAAoYBMGgBgG5bDUmmCNADANixnxWiKuwEACFVk0gAA27AclkoTpAEAtmE5K0ZT3A0AQKgikwYA2IblsFSaIA0AsA3LYUGa4m4AAEIUmTQAwDYsZyXSBGkAgH1YDovSFHcDABCiyKQBALZhOSuRJkgDAOzDcliUprgbAIAQRSYNALANy1mJNEEaAGAfYQ6L0hR3AwAQosikAQC2YTkrkSZIAwDsw3JYlKa4GwCAEEUmDQCwjTBnJdIEaQCAfVgUdwMAgFBAJg0AsA3LWYk0QRoAYB+WOCtKU9wNAECIIpMGANhGmLMSaYI0AMA+LIdVSlPcDQBAiCKTBgDYhuWsRJpMGgBgr1tVhgVpSonBgwdL1apVJUuWLJIrVy5p2bKl7Nq1K9nXTJ061RTPe08REREpO94ULQ0AgAOtWrVKunXrJuvWrZNly5bJxYsX5e6775Zz584l+7rIyEg5fPiwZ9q/f3+KtktxNwDANqw0Ku5esmRJoixZM+pNmzZJnTp1knydZs958uS57u2SSQMAbMNKUHz8b6Z/49SpU+ZvdHR0ssudPXtWChcuLAULFpQWLVrIjh07UrQdgjQAwJHi4+Pl9OnTPpPOu5YrV65Ir1695K677pIyZcokuVyJEiVkypQpsnDhQpk+fbp5Xc2aNeXgwYMB7yNBGgBgG5YVvEkbg0VFRflMOu9atG56+/btMnPmzGSXi4mJkTZt2kiFChWkbt26Mm/ePMmZM6dMnDgx4OOlThoAYBthQayUjo2Nld69e/vMCw8PT/Y13bt3l0WLFsnq1aulQIECKdrerbfeKhUrVpTdu3cH/BqCNADAkTQgXysou7lcLunRo4fMnz9fVq5cKUWKFEnx9i5fvizbtm2TZs2aBfwagjQAwDasNNquFnHPmDHD1C9rX+kjR46Y+VpEniFDBvNvLdrOnz+/p8i8f//+UqNGDSlWrJicPHlShg4darpgdezYMeDtEqQBALZhpVEfrPHjx5u/9erV85n/4YcfSrt27cy/4+LiJCzsn6ZeJ06ckE6dOpmAni1bNqlcubKsWbNGSpUqFfB2LZfm8CEgQ8Xuab0LQKo7sWFMWu8CkOoiUjH9a/3RlqCt65M2FSTUkUkDAGwjzGFjdxOkAQC2YTnsDhv0kwYAIESRSQMAbMNyViJNkAYA2IflsChNcTcAACGKTBoAYBthzkqkCdIAAPuwKO4GAAChgEwaAGAbljgLQRoA4MhbVdoBxd0AAIQoMmkAgG1YzkqkCdIAAPuwHBalKe4GACBEkUkDAGzDclYiTZAGANhHmMOiNMXdAACEKDJpAIBtWM5KpAnSAAD7sBwWpSnuBgAgRIVMJn1iw5i03gUAQIgLE2cJmSANAMC1WBR3AwCAUEAmDQCwjTBnJdIEaQCAfYQ5LEhT3A0AQIgikwYA2IblsIZjBGkAgG2EOStGU9wNAECoIpMGANiG5bBMmiANALCNMIdFaYq7AQAIUQRpAICtglZYkKaUGDx4sFStWlWyZMkiuXLlkpYtW8quXbuu+bo5c+bInXfeKREREVK2bFlZvHhxio8XAABbsKzgTSmxatUq6datm6xbt06WLVsmFy9elLvvvlvOnTuX5GvWrFkjrVu3lg4dOsjmzZtNYNdp+/btgR+vy+VySQg4fymt9wAAEAwRqdja6dUvfgnaugY2veO6X3v8+HGTUWvwrlOnjt9lHn30URPEFy1a5JlXo0YNqVChgkyYMCGg7ZBJAwBs1XAsLEjTv3Hq1CnzNzo6Osll1q5dK40aNfKZ16RJEzM/ULTuBgDYhhXExt3x8fFm8hYeHm6m5Fy5ckV69eold911l5QpUybJ5Y4cOSK5c+f2maePdX6gyKQBAI40ePBgiYqK8pl03rVo3bTWK8+cOTPV95FMGgDgyGFBY2NjpXfv3j7zrpVFd+/e3dQxr169WgoUKJDssnny5JGjR4/6zNPHOj9QZNIAAEfWSYeHh0tkZKTPlFSQ1jbWGqDnz58vX3/9tRQpUuSa+xoTEyPLly/3mactw3V+oMikAQAIoIh7xowZsnDhQtNX2l2vrEXkGTJkMP9u06aN5M+f31Nk3rNnT6lbt64MHz5cmjdvborHN27cKJMmTZJAkUkDAGzDSqN+0uPHjzctuuvVqyd58+b1TLNmzfIsExcXJ4cPH/Y8rlmzpgnsGpTLly8vc+fOlQULFiTb2CzR8dJPGgBgl37SA5fvDtq6Xm1YTEIdmTQAACGKOmkAgG1Y4qy7YBGkAQCO7IJlBxR3AwAQosikAQC2EeawTJogDQCwDSuYg3fbAMXdAACEKDJpAIBthDkrkSZIAwDsw3JYkKa4GwCAEEUmDQCwjTCHpdIEaQCAbYQ5K0ZT3A0AQKgikwYA2IblsEyaIA0AsI0wh91gg+JuAABCFJk0AMA2LGcl0gRpAIB9hDksSFPcDQBAiCKTBgDYRpjDyrsJ0gAA27CcFaMp7gYAIFSRSQMAbCPMYak0QRoAYBuWs2I0xd0AAIQqMmkAgG2EibMQpAEAtmE5rLzbaRclAADYBpk0AMA2LHEWgjQAwDbCKO4GAAChgEwaAGAbljgLQRoAYBuWw6I0xd0AAARg9erVct9990m+fPlMV7AFCxYku/zKlSvNcgmnI0eOSKDIpAEAtmGlYSp97tw5KV++vDz11FPy4IMPBvy6Xbt2SWRkpOdxrly5An4tQRoAYBthabjtpk2bmimlNChnzZr1urZJcTcAAKmoQoUKkjdvXmncuLF89913KXotmTQAwJHF3fHx8WbyFh4ebqZg0MA8YcIEqVKlitnO5MmTpV69erJ+/XqpVKlSQOsgkwYA2IYVxGnw4MESFRXlM+m8YClRooQ8/fTTUrlyZalZs6ZMmTLF/B05cmTA6yCTBgA4UmxsrPTu3dtnXrCy6KRUq1ZNvv3224CXJ0gDABxZ3B0exKLtQG3ZssUUgweKIA0AsI2wNNz22bNnZffu3Z7He/fuNUE3OjpaChUqZDLzQ4cOyUcffWSeHzVqlBQpUkRKly4t58+fN3XSX3/9tXz55ZcBb5MgDQBAADZu3Cj169f3PHYXlbdt21amTp0qhw8flri4OM/zFy5ckD59+pjAnTFjRilXrpx89dVXPuu4FsvlcrkkBJy/lNZ7AAAIhohUTP/mbw18tK5reaBcHgl1ZNIAANuwxFnoggUAQIgikwYA2IblsFSaIA0AsI0whxV4U9wNAECIIpMGANiG5axEmiANALAPi+JuAAAQCsikAQC2YTkrkSZIAwDsI4zibgAAEArIpAEAtmE5K5EmSAMA7MNyWJCmuBsAgBBFJg0AsA2LhmPXZ8+ePdKgQYNgrQ4AgETCrOBNjgrSZ8+elVWrVgVrdQAAOF7Axd3vvvtuss8fOnQoGPsDAECSLIcVdwccpHv16iV58+aV9OnT+33+woULwdwvAAAcL+AgXbhwYXn77belVatWfp/fsmWLVK5cOZj7BgCAD7pgJUED8KZNm5J83rIscblcwdovAAD8FncH67+bKpPu37+//PXXX0k+X6pUKdm7d2+w9gsAAMcLOEhrEE7OrbfeaorEAQBILWH2SICDhhHHbOKD9yfK460ekpiqFaVe7Rjp1eMZ2bf3N59lDsTFSa9nu0m9WjWkZrVK8kLvnvLH77/7LNO0cQMpX7qEz/TB+5N8lvnu22/kydatrm6rVg3p3bOHHDp0MFFDwfdGj5R7GtWXKhXKmPXOnzc3Fd8B3Iw2bdwgPZ7pIo3q1TLfxa+Xf+Xz/FfLvpSnOz0ldWpWN8/v/PnnJNel1W3PPN0x0XpOnjwhXTt3MNvQ7+rdDevKoLf6m26jbhu+X5/od6HT78eP+2zj6NGjEvvS82Z/qlUqJw+1vE92bN8W1PcEybMo7kYo2rjhe3m09RNSumxZuXzpsrw3eoR06dRB5n32uWTMmNFURXTp/JTcUeJOeX/KNPOase+Nlh7dusj0T2ZLWNg/12PPdH9WHnr4nwaAGTNl8vz74MED5gLgP23by+C3h8nZs2dk6NuDTaCeNXe+ZzlzAfDHH/LmgIFSsFAhczK7cuXKDXs/cHP4+++/pESJEtLywYekd8/ufp+vWLGSNGnSVPq98Vqy65r+0TTTNiahMCtM6jdoKN2f7SXZoqPNxeygt/rJW/1OyZChw32WXfj5EsmcKbPncXT27J5/nz51Sto92VqqVKsuYye8L9mis0nc/v0SGRl1nUcPXBtB2ibGT/rA53H/gUOkfu0Y+fmnHVK5SlXZsvkH+d+hQzJr7gLJnPnqSWbAoLeldkxV+X79OqkRU9Pz2kyZMkmOnDn9bufnHTtMsNUTmjuwt2n3lAncFy9eNNUa332z2mRAny/5SqKyZjXL5M9fIBWPHjerWrXrmikp993f0vxNWJKTkGbYH02bIp/M+lQa1qvl81xkVJS0euxxz+N8+fKbx9M+9P1Nqejo7BIZGel3G1M+eF9y58kjAwYO9swrUKBgsvuF4LPskQAHDcXdNnX2zBnPCchd/KxZhHc/9vDwcBNoN//g2yp/yuT3TXFdq4daytQpk+XSpUue50qWLm3Ws2D+p3L58mU5c+aMfP5/C6V6TE0ToNXKFV9LqdJl5MMpk6VR/dpyX7MmMnzo23L+/PkbdPTAP/7++2+JfbGPvPJa3yQvPr0dO3ZUvv5qmbm4TejRh1pKw7q15OmO7RP9blat+FpKly4jzz/3rKly0t/Pp3NmB/VYcG1WEKebKkjruNwnT55M3b1BQDTTfeftQVKhYiUpXvwOM69c+QqSIUMGGTV8qDlpafG3Bk4NtMe96tVaP/EfeXvYCJn84TR5uNWjMvn9iTJy+FCfzGDC+1NMfXPVimWlVo0qph5u6PBRPkXiegLbvftXGTl6rLz48ivy1ZdLZeCAfjf4nQDEVMeUr1hR6jdolOxyLz3fW6pXLi+N69cxpUlv9h/oeS5nzpzy2hv9ZPiod82kGXPH9m1MSZX39372rE+kUOHbTMlWq0dby9uD35LPFvxTDQSkWZBeuXJl0EYVi4+Pl9OnT/tMOg+B0fq0Pb/+Ku8MG+mZFx0dLUNHjJZVq1aYBl8aXM+cOS0lS5WWMK/mkG3atZeq1aqbums9yfR54SWZOWO657PVuuV+b7wu99/fUj6eNVemTJtuMmjNHtz94K+4XCbb1jrrsuXKSe06daXPiy/L/y2cTzaNG2rl18tlw/p18uJLr1xz2RdeipWZc+bJ6PfGyYEDB2TY2/8UW99W5HZ5pNVjpoRIL377vzVYyleoKP/9aKpnmStXXOb39Gyv3lKyZClzkfvgw61kzuyZqXZ8SCzMsoI22UGaFHcPHjxYoqKifCa9Gsa1aavU1atWyvsfTjNX+95q3lXL1BOv+GaNrPx2nQwaMlSOHT2abL1Z2XLlTXH3//5/nd/MTz6WLJkzy3PPv2hORFokqOtZv26tbNv6o1kmZ46ckitXbsmSJYtnPbffXtQE8aNHj6TasQMJaXuLAwfipFZMValUrpSZVJ9ePaRDu//4LKtF4UVuLyr1GjSU19/oZ7Li48ePJbnuMmXLmkZm3tn27UWL+ixz++23y+HD/wv6cSFplsOKu1PUcOynn36SI0eSPwmXK1fumuuJjY2V3r17+8xzpQtPya44jgbAwQMHyNfLl8kHU/+bbODNli3a/NXA+ueff0i9+knfQnTXzp9NvbU2mFGaCVteLcFVWLqrj92ttzXTWPblEvnr3DlPy/D9+/ea9eTO7XvhAKSmpzp2lgcefsRn3sMt75PnX4qVuvXqJ/k6d6lQcqWDu3bu9Knj1u/9vgQDNu3ft880RANCIkg3bNjQ79Cf7iFB9a/WgV6LNmjSydv5f9ouwY9BA/rJF4sXyaj3xkmmjJk8/TczZ8kiERER5t/a2EszWg3SP/64Wd4ZPEiebNPOFOWpH7dsNtlw1Wo1TJ2cLqMlGM3vvd/TAE2Lrqd/NFUmjBsjTZvfawLxu6NGmBPRnSWvZinNmt8rkyaOk76vxUrXbs+afqgjhg2Vlg885NkXIBD6/YrzylYPHTxoWmpr6VrefPnk1MmTcvjwYU/Gu2/f1SCZI0cOE0DdU0J58+bzXMh+s3qV/PHH71K6TFnTXXHP7t0yctg7Jui6eyXodz5/gQJStGhxib8QL/PnzjFZurbPcHuyTVtp+2RrmTxpgtzdpKls37ZV5s6dLX3f7J/q7xO82CUFDhLLFeCA25olff/996bIJznXO+oYQTp5OrCCP1p31uKBB82/R40YZhqxnDp1SvLlz2/q2P7Ttp2n76g2gtHGXToIimYQeoK69/4Wpk+0d6vwLxZ/blp9a5YQkSFCypevIL16P2+KCt32/rZHhgx6y3T90m5YetLSblsEaaSEDiKiDbQSur/FAzJg0BBZOH+euRhMqMsz3aVrtx5J/lZGvjtWGjS82pBMg+2Yd0fJb3t2m+997jx5pWGjxiYLd3e3+vCD901LbW35HRGRQYrfcYc83bWbVKtew2fdq1auMBetcfv3maD+nzbt5aFH/N90yMkiUrFz7/o9p4K2rupFo26uIK1F3bly5UqVHSFIA8DN4WYN0qtXr5ahQ4eam01pCc/8+fOlZcurffmTa3St1bs7duyQggULymuvvSbt2rULeJv0kwYA2IZlBW9KqXPnzkn58uVl7NixAS2vN51q3ry51K9f39zOuVevXtKxY0dZunRpwNsM+Hqnbt26PkWiAAA4qUq6adOmZgrUhAkTpEiRIjJ8+NXhZ0uWLCnffvutjBw5Upo0aRLcIL148WJZvny53HvvvZ4W2t59m9OlSycDBgygThIAABFZu3atNGrkO8iOBmfNqAMVcJCeNm2afP75554gPWbMGCldurQZ5Urt3LlT8uXLJ88991zgRwAAQBql0vHx8YkG0vLX++h6aTuu3Llz+8zTxzqAl44M6Y6fQamTnj59unTu3Nln3owZM2TFihVm0sr02bMZxxYAYI9bVQ72M7CWzgslAQfpPXv2SNmyZT2PtVjb+/aH1apVM4OdAABgB7GxsabLqvek84IlT5485t4H3vSxdv0LJItOUXG33lzDu1jA+6YN7tGoGH8bAJCarCAWdwezaNufmJgY057L27Jly8z8oGfSBQoUkO3btyf5/NatW80yAADcjGN3nz171nSl0sndxUr/7R41T7PwNm3+GZynS5cu8ttvv8mLL75o2m2NGzfOVAunpO1WwEG6WbNm0rdvX793OdIK8H79+pn+YAAA3Iw2btwoFStWNJPSQUr03xoblQ5w4j3MrXa/0gbXmj1r/2rtijV58uSAu1+laMQxLUevUKGC6SvdvXt3ueOOq/cx3rVrl2nprXdS2rx5c6KWbIFixDEAuDmk5ohjP+w/HbR1VSp8dVjYUBZwkHan9l27djVXBe6X6bjQjRs3Nmm83rbtehGkAeDmkJpBevP+M0FbV8XC/9xu96YI0m5//vmn7N692/y7WLFiEh199daI/wZBGgBuDgTpNA7SqYEgDQA3h9QM0lvighekKxQK/SCdim8lAADBZYmzcBcsAABCFJk0AMA+LHEUgjQAwDYsh0VpirsBAAhRZNIAAEeO3W0HBGkAgG1Y4iwUdwMAEKLIpAEA9mGJoxCkAQC2YTksSlPcDQBAiCKTBgDYhuWsRJogDQCwD0ucheJuAABCFJk0AMA+LHEUgjQAwDYsh0VpirsBAAhRZNIAANuwnJVIE6QBAPZhibNQ3A0AQIgikwYA2IcljkKQBgDYhuWwKE1xNwAAIYpMGgBgG5azEmmCNADAPixxFoq7AQAIUWTSAAD7sMRRCNIAANuwHBalKe4GACBEkUkDAGzDclYiTSYNALAPK4jT9Rg7dqzcdtttEhERIdWrV5fvv/8+yWWnTp0qlmX5TPq6lCBIAwAQgFmzZknv3r3ljTfekB9++EHKly8vTZo0kWPHjiX5msjISDl8+LBn2r9/v6QEQRoAYB9W2qXSI0aMkE6dOkn79u2lVKlSMmHCBMmYMaNMmTIl6d21LMmTJ49nyp07d4q2SZAGANiqdbcVpP/i4+Pl9OnTPpPO8+fChQuyadMmadSokWdeWFiYebx27dok9/fs2bNSuHBhKViwoLRo0UJ27NiRouMlSAMAHGnw4MESFRXlM+k8f37//Xe5fPlyokxYHx85csTva0qUKGGy7IULF8r06dPlypUrUrNmTTl48GDA+0jrbgCAI1t3x8bGmjpmb+Hh4UFbf0xMjJncNECXLFlSJk6cKAMGDAhoHQRpAIBtWEFclwbkQINyjhw5JF26dHL06FGf+fpY65oDceutt0rFihVl9+7dAe8jxd0AAFxD+vTppXLlyrJ8+XLPPC2+1sfe2XJytLh827ZtkjdvXgkUmTQAwDasNBzMRIvG27ZtK1WqVJFq1arJqFGj5Ny5c6a1t2rTpo3kz5/fU6/dv39/qVGjhhQrVkxOnjwpQ4cONV2wOnbsGPA2CdIAABux0mzLjz76qBw/flz69u1rGotVqFBBlixZ4mlMFhcXZ1p8u504ccJ02dJls2XLZjLxNWvWmO5bgbJcLpdLQsD5S2m9BwCAYIhIxfTv4IkLQVtXgWzpJdSRSQMAbMNy2NjdBGkAgG1Y4iy07gYAIESRSQMAbMNyWCpNkAYA2IblsAJvirsBAAhRZNIAAPuwxFEI0gAA27DEWSjuBgAgRJFJAwBsw3JYKk2QBgDYhuWwAm+KuwEACFFk0gAA+7DEUQjSAADbsMRZKO4GACBEkUkDAGzDclgqTZAGANiG5bACb4q7AQAIUWTSAADbsJyVSJNJAwAQqgjSAACEKIq7AQC2YTmsuJsgDQCwDYvW3QAAIBSQSQMAbMNyViJNkAYA2IclzkJxNwAAIYpMGgBgH5Y4CkEaAGAblsOiNMXdAACEKDJpAIBtWM5KpAnSAAD7sMRZKO4GACBEkUkDAOzDEkchSAMAbMNyWJSmuBsAgBBFJg0AsA3LWYm0WC6Xy5XWO4EbLz4+XgYPHiyxsbESHh6e1rsDpAq+57A7grRDnT59WqKiouTUqVMSGRmZ1rsDpAq+57A76qQBAAhRBGkAAEIUQRoAgBBFkHYobUTzxhtv0JgGNzW+57A7Go4BABCiyKQBAAhRBGkAAEIUQRoAgBBFkEYi7dq1k5YtW6b1bgCpiu857IAgbaMTimVZZkqfPr0UK1ZM+vfvL5cuXUqT/dm6davUrl1bIiIipGDBgvLOO++kyX7g5hJK3/Pz58+b/SlbtqzccsstBHSkCYK0jdxzzz1y+PBh+fXXX6VPnz7y5ptvytChQ/0ue+HChVQdavHuu++WwoULy6ZNm8w+6L5MmjQp1bYJ5wiV7/nly5clQ4YM8uyzz0qjRo1SbTtAcgjSNqJ9PfPkyWOCY9euXc2J47PPPvMpuhs4cKDky5dPSpQoYeYfOHBAWrVqJVmzZpXo6Ghp0aKF7Nu3z+dE1Lt3b/N89uzZ5cUXX5Rr9cr7+OOPzclxypQpUrp0aXnsscfMiWzEiBGp/A7ACULle54pUyYZP368dOrUyewPkBYI0jamV/nemcTy5ctl165dsmzZMlm0aJFcvHhRmjRpIlmyZJFvvvlGvvvuO8mcObPJVNyvGz58uEydOtUE3G+//Vb+/PNPmT9/frLbXbt2rdSpU8cUR7rpdnTbJ06cSMUjhhOl1fccCAXcT9qGNAPQE9XSpUulR48ePlf+kydP9gTP6dOny5UrV8w8reNTH374ockmVq5caYqsR40aZW7j9+CDD5rnJ0yYYNabnCNHjkiRIkV85uXOndvzXLZs2YJ+zHCetP6eA6GAIG0jmjVohqCZg56UHn/8cVNf56YNXLyz2x9//FF2795tMoyEDWL27Nljbt+ndX/Vq1f3PKcNZKpUqXLNokAgtfA9B/5BkLaR+vXrmzoyPUFpfZyeaLxphuHt7NmzUrlyZVOHnFDOnDmvez+0fu7o0aM+89yPqbvDzfI9B0IBddI2oicn7ZJSqFChRCcufypVqmRayObKlcu8znuKiooyU968eWX9+vWe12hXF22xnZyYmBhZvXq1yXTctH5QG/FQ1I2b5XsOhAKC9E3siSeekBw5cpiWrtqgZu/evaaOTltiHzx40CzTs2dPGTJkiCxYsEB27twpzzzzjJw8eTLZ9Wrxo2Y5HTp0kB07dsisWbNk9OjRpvUscLN8z9VPP/0kW7ZsMQ3NtNhc/60TcKNQ3H0Ty5gxo8l4X3rpJdNg5syZM5I/f35p2LChREZGmmW0H6rW17Vt21bCwsLkqaeekgceeMCckJKimcmXX34p3bp1M8WMeoLs27evdO7c+QYeHZC633PVrFkz2b9/v+dxxYoVzV/qsnGjcKtKAABCFMXdAACEKII0AAAhiiANAECIIkgDABCiCNIAAIQogjQAACGKIA0AQIgiSAMAEKII0gAAhCiCNAAAIYogDQBAiCJIAwAgoen/AQhmOol5AojPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pred_dir = r\"D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_results/Dataset124_ISLES22_2CH/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation\"\n",
    "gt_dir   = r\"D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_raw/Dataset124_ISLES22_2CH/labelsTr\"\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "def dice_coef(gt, pred):\n",
    "    intersection = np.sum((gt == 1) & (pred == 1))\n",
    "    return (2.0 * intersection) / (np.sum(gt == 1) + np.sum(pred == 1) + 1e-8)\n",
    "\n",
    "\n",
    "for file in os.listdir(pred_dir):\n",
    "    if not file.endswith(\".nii.gz\"):\n",
    "        continue\n",
    "\n",
    "    case_id = file.replace(\".nii.gz\", \"\")\n",
    "\n",
    "    pred_path = os.path.join(pred_dir, file)\n",
    "    gt_path   = os.path.join(gt_dir, case_id + \".nii.gz\")\n",
    "\n",
    "    if not os.path.exists(gt_path):\n",
    "        print(\"Missing GT for:\", case_id)\n",
    "        continue\n",
    "\n",
    "    pred_img = sitk.ReadImage(pred_path)\n",
    "    gt_img   = sitk.ReadImage(gt_path)\n",
    "\n",
    "    pred = sitk.GetArrayFromImage(pred_img)\n",
    "    gt   = sitk.GetArrayFromImage(gt_img)\n",
    "\n",
    "    pred_bin = (pred > 0.5).astype(np.uint8)\n",
    "    gt_bin   = (gt > 0).astype(np.uint8)\n",
    "\n",
    "    # Flatten for sklearn\n",
    "    p = pred_bin.flatten()\n",
    "    g = gt_bin.flatten()\n",
    "\n",
    "    dice = dice_coef(g, p)\n",
    "    acc = accuracy_score(g, p)\n",
    "    prec = precision_score(g, p, zero_division=0)\n",
    "    rec = recall_score(g, p, zero_division=0)\n",
    "    f1 = f1_score(g, p, zero_division=0)\n",
    "    iou = jaccard_score(g, p, zero_division=0)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(g, p, labels=[0,1]).ravel()\n",
    "\n",
    "    metrics_list.append({\n",
    "        \"case\": case_id,\n",
    "        \"dice\": dice,\n",
    "        \"iou\": iou,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(metrics_list)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Save metrics to CSV\n",
    "df.to_csv(\"nnunet_validation_metrics.csv\", index=False)\n",
    "print(\"\\nSaved: nnunet_validation_metrics.csv\")\n",
    "\n",
    "# --------- Plot mean confusion matrix ----------\n",
    "mean_TP = df[\"TP\"].sum()\n",
    "mean_FP = df[\"FP\"].sum()\n",
    "mean_FN = df[\"FN\"].sum()\n",
    "mean_TN = df[\"TN\"].sum()\n",
    "\n",
    "cm = np.array([[mean_TN, mean_FP],\n",
    "               [mean_FN, mean_TP]])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred 0\",\"Pred 1\"], yticklabels=[\"GT 0\",\"GT 1\"])\n",
    "plt.title(\"Confusion Matrix (Aggregated)\")\n",
    "plt.show()\n",
    "\n",
    "# --------- Boxplots for metrics ---------\n",
    "plt.figure(figsize=(12,6))\n",
    "df[[\"dice\",\"f1_score\",\"precision\",\"recall\",\"iou\",\"accuracy\"]].boxplot()\n",
    "plt.title(\"Metric Distribution Across Validation Cases\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case ID              | Spacing (mm)         | Pred Vol (ml)   | AVD (ml)  \n",
      "--------------------------------------------------------------------------------\n",
      "ISLES22_0010.nii.gz  | [2.00, 2.00, 2.00]   | 2.976           | 0.392\n",
      "ISLES22_0011.nii.gz  | [2.00, 2.00, 2.00]   | 10.408          | 0.784\n",
      "ISLES22_0017.nii.gz  | [2.00, 2.00, 2.00]   | 11.800          | 3.632\n",
      "ISLES22_0019.nii.gz  | [2.00, 2.00, 2.00]   | 70.664          | 2.088\n",
      "ISLES22_0021.nii.gz  | [2.00, 2.00, 2.00]   | 14.088          | 3.632\n",
      "ISLES22_0028.nii.gz  | [2.00, 2.00, 2.00]   | 6.672           | 0.600\n",
      "ISLES22_0031.nii.gz  | [2.00, 2.00, 2.00]   | 89.920          | 3.152\n",
      "ISLES22_0034.nii.gz  | [2.00, 2.00, 2.00]   | 1.312           | 0.072\n",
      "ISLES22_0041.nii.gz  | [2.00, 2.00, 2.00]   | 3.976           | 1.248\n",
      "ISLES22_0048.nii.gz  | [2.00, 2.00, 2.00]   | 48.512          | 6.488\n",
      "ISLES22_0051.nii.gz  | [2.00, 2.00, 2.00]   | 2.696           | 0.424\n",
      "ISLES22_0053.nii.gz  | [2.00, 2.00, 2.00]   | 0.832           | 0.112\n",
      "ISLES22_0055.nii.gz  | [2.00, 2.00, 2.00]   | 23.624          | 2.216\n",
      "ISLES22_0068.nii.gz  | [2.00, 2.00, 2.00]   | 0.976           | 2.712\n",
      "ISLES22_0069.nii.gz  | [2.00, 2.00, 2.00]   | 0.168           | 0.032\n",
      "ISLES22_0072.nii.gz  | [2.00, 2.00, 2.00]   | 10.472          | 2.344\n",
      "ISLES22_0074.nii.gz  | [2.00, 2.00, 2.00]   | 2.336           | 2.968\n",
      "ISLES22_0086.nii.gz  | [2.00, 2.00, 2.00]   | 46.280          | 0.480\n",
      "ISLES22_0093.nii.gz  | [2.00, 2.00, 2.00]   | 0.392           | 0.056\n",
      "ISLES22_0094.nii.gz  | [2.00, 2.00, 2.00]   | 4.112           | 0.424\n",
      "ISLES22_0104.nii.gz  | [2.00, 2.00, 2.00]   | 83.432          | 6.280\n",
      "ISLES22_0105.nii.gz  | [2.00, 2.00, 2.00]   | 17.608          | 4.152\n",
      "ISLES22_0110.nii.gz  | [2.00, 2.00, 2.00]   | 7.160           | 2.016\n",
      "ISLES22_0118.nii.gz  | [2.00, 2.00, 2.00]   | 3.728           | 2.656\n",
      "ISLES22_0121.nii.gz  | [2.00, 2.00, 2.00]   | 4.000           | 0.096\n",
      "ISLES22_0123.nii.gz  | [2.00, 2.00, 2.00]   | 93.968          | 1.144\n",
      "ISLES22_0135.nii.gz  | [2.00, 2.00, 2.00]   | 1.488           | 0.032\n",
      "ISLES22_0137.nii.gz  | [1.35, 1.35, 4.40]   | 0.958           | 1.305\n",
      "ISLES22_0140.nii.gz  | [2.00, 2.00, 2.00]   | 60.768          | 80.600\n",
      "ISLES22_0146.nii.gz  | [2.00, 2.00, 2.00]   | 9.984           | 11.032\n",
      "ISLES22_0148.nii.gz  | [2.00, 2.00, 2.00]   | 2.560           | 0.280\n",
      "ISLES22_0151.nii.gz  | [2.00, 2.00, 2.00]   | 0.000           | 0.000\n",
      "ISLES22_0160.nii.gz  | [2.00, 2.00, 2.00]   | 1.728           | 2.704\n",
      "ISLES22_0161.nii.gz  | [1.80, 1.80, 4.80]   | 91.005          | 4.029\n",
      "ISLES22_0168.nii.gz  | [2.00, 2.00, 2.00]   | 33.128          | 2.592\n",
      "ISLES22_0181.nii.gz  | [2.00, 2.00, 2.00]   | 6.448           | 9.760\n",
      "ISLES22_0182.nii.gz  | [1.80, 1.80, 4.80]   | 0.294           | 1.333\n",
      "ISLES22_0186.nii.gz  | [1.80, 1.80, 4.80]   | 6.029           | 5.099\n",
      "ISLES22_0187.nii.gz  | [1.80, 1.80, 4.80]   | 6.494           | 0.310\n",
      "ISLES22_0188.nii.gz  | [1.15, 1.15, 4.80]   | 6.857           | 3.201\n",
      "ISLES22_0196.nii.gz  | [2.00, 2.00, 2.00]   | 12.544          | 0.928\n",
      "ISLES22_0197.nii.gz  | [1.80, 1.80, 4.80]   | 5.331           | 0.558\n",
      "ISLES22_0201.nii.gz  | [1.97, 1.97, 2.00]   | 180.896         | 33.498\n",
      "ISLES22_0205.nii.gz  | [2.00, 2.00, 2.00]   | 29.800          | 7.064\n",
      "ISLES22_0207.nii.gz  | [1.15, 1.15, 4.80]   | 15.377          | 1.765\n",
      "ISLES22_0212.nii.gz  | [2.00, 2.00, 2.00]   | 0.312           | 0.792\n",
      "ISLES22_0220.nii.gz  | [2.00, 2.00, 2.00]   | 4.400           | 1.040\n",
      "ISLES22_0235.nii.gz  | [2.00, 2.00, 2.00]   | 9.768           | 2.248\n",
      "ISLES22_0238.nii.gz  | [1.15, 1.15, 4.80]   | 14.318          | 1.449\n",
      "ISLES22_0247.nii.gz  | [2.00, 2.00, 2.00]   | 15.888          | 2.368\n",
      "--------------------------------------------------------------------------------\n",
      "FINAL ISLES METRIC:\n",
      "Mean AVD:   4.484 ml\n",
      "Median AVD: 1.890 ml   (recommended for ISLES)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "\n",
    "pred_folder = r\"D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_results\\Dataset124_ISLES22_2CH/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation\"\n",
    "gt_folder   = r\"D:/Capstone/Experiment 3/nnUNet_2_channel/nnUNet_raw\\Dataset124_ISLES22_2CH/labelsTr\"\n",
    "\n",
    "avd_list = []   # ← FIXED (line 11)\n",
    "\n",
    "print(f\"{'Case ID':<20} | {'Spacing (mm)':<20} | {'Pred Vol (ml)':<15} | {'AVD (ml)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Iterate through predictions\n",
    "for filename in sorted(os.listdir(pred_folder)):\n",
    "\n",
    "    if filename.endswith(\".nii.gz\"):\n",
    "        pred_path = os.path.join(pred_folder, filename)\n",
    "        gt_path   = os.path.join(gt_folder, filename)\n",
    "\n",
    "        # Sanity check: GT exists?\n",
    "        if not os.path.exists(gt_path):\n",
    "            print(f\"⚠ GT not found for {filename}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Load files\n",
    "        pred_img = nib.load(pred_path)\n",
    "        gt_img   = nib.load(gt_path)\n",
    "\n",
    "        # Extract patient-specific spacing (CRITICAL)\n",
    "        spacing = pred_img.header.get_zooms()   # (x, y, z)\n",
    "        voxel_vol_mm3 = np.prod(spacing)\n",
    "\n",
    "        # Compute volumes\n",
    "        vol_pred_mm3 = np.sum(pred_img.get_fdata() > 0) * voxel_vol_mm3\n",
    "        vol_gt_mm3   = np.sum(gt_img.get_fdata() > 0) * voxel_vol_mm3\n",
    "\n",
    "        # Convert → ml\n",
    "        vol_pred_ml = vol_pred_mm3 / 1000\n",
    "        vol_gt_ml   = vol_gt_mm3 / 1000\n",
    "\n",
    "        # Absolute Volume Difference\n",
    "        avd = abs(vol_pred_ml - vol_gt_ml)\n",
    "        avd_list.append(avd)\n",
    "\n",
    "        spacing_str = f\"[{spacing[0]:.2f}, {spacing[1]:.2f}, {spacing[2]:.2f}]\"\n",
    "\n",
    "        print(f\"{filename:<20} | {spacing_str:<20} | {vol_pred_ml:<15.3f} | {avd:.3f}\")\n",
    "\n",
    "# === FINAL REPORT ===\n",
    "print(\"-\" * 80)\n",
    "print(\"FINAL ISLES METRIC:\")\n",
    "print(f\"Mean AVD:   {np.mean(avd_list):.3f} ml\")\n",
    "print(f\"Median AVD: {np.median(avd_list):.3f} ml   (recommended for ISLES)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Detected input folder: D:/Capstone/Experiment 3/TEST_INPUT\n",
      "🔍 Found 1 NIfTI files. Checking modalities...\n",
      "\n",
      "🆔 Auto-detected Case ID: sub_strokecase0002 \n",
      "\n",
      "✔ Detected sub-strokecase0002_ses-0001_dwi.nii.gz → modality 0 → renamed to sub_strokecase0002_0000.nii.gz\n",
      "\n",
      "---------------------------\n",
      "📦 SUMMARY\n",
      "---------------------------\n",
      "DWI   (0000): sub_strokecase0002_0000.nii.gz\n",
      "⚠️ ADC missing (modality 1)\n",
      "⚠️ FLAIR missing (modality 2)\n",
      "\n",
      "📁 Ready for nnU-Net input: D:/Capstone/Experiment 3/TEST_READY\n",
      "🎉 Auto-preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "INPUT = r\"D:/Capstone/Experiment 3/TEST_INPUT\"\n",
    "OUTPUT = r\"D:/Capstone/Experiment 3/TEST_READY\"  # Folder nnUNet will read from\n",
    "\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# MODALITY KEYWORD RULES\n",
    "# ---------------------------\n",
    "modality_map = {\n",
    "    \"dwi\": 0,\n",
    "    \"diff\": 0,\n",
    "    \"adc\": 1,\n",
    "    \"apparent\": 1,\n",
    "    \"flair\": 2,\n",
    "    \"t2\": 2\n",
    "}\n",
    "\n",
    "print(\"📌 Detected input folder:\", INPUT)\n",
    "files = [f for f in os.listdir(INPUT) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "if len(files) == 0:\n",
    "    raise ValueError(\"❌ No .nii.gz files found in TEST_INPUT!\")\n",
    "\n",
    "print(f\"🔍 Found {len(files)} NIfTI files. Checking modalities...\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# AUTO-DETECT CASE ID\n",
    "# ---------------------------\n",
    "# Remove known modality keywords & session info to isolate patient ID\n",
    "def extract_case_id(filename):\n",
    "    base = filename.replace(\".nii.gz\", \"\")\n",
    "\n",
    "    # remove typical modality suffixes\n",
    "    cleaned = re.sub(r\"(dwi|adc|flair|t2|diff|apparent|ses-\\d+|run-\\d+)\", \"\", base, flags=re.IGNORECASE)\n",
    "    cleaned = cleaned.replace(\"__\", \"_\").replace(\"-\", \"_\")\n",
    "    return cleaned.strip(\"_\")\n",
    "\n",
    "case_id = extract_case_id(files[0])\n",
    "print(\"🆔 Auto-detected Case ID:\", case_id, \"\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# PROCESS FILES\n",
    "# ---------------------------\n",
    "\n",
    "assigned = {0: None, 1: None, 2: None}\n",
    "\n",
    "for f in files:\n",
    "    fname = f.lower()\n",
    "\n",
    "    detected = None\n",
    "    for key, mid in modality_map.items():\n",
    "        if key in fname:\n",
    "            detected = mid\n",
    "            break\n",
    "\n",
    "    if detected is None:\n",
    "        print(f\"⚠️ WARNING: Could NOT detect modality for {f}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    new_name = f\"{case_id}_{detected:04d}.nii.gz\"\n",
    "    src = os.path.join(INPUT, f)\n",
    "    dst = os.path.join(OUTPUT, new_name)\n",
    "\n",
    "    shutil.copy(src, dst)\n",
    "    assigned[detected] = new_name\n",
    "\n",
    "    print(f\"✔ Detected {f} → modality {detected} → renamed to {new_name}\")\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "print(\"📦 SUMMARY\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "if assigned[0]:\n",
    "    print(f\"DWI   (0000): {assigned[0]}\")\n",
    "else:\n",
    "    print(\"❌ DWI missing (modality 0)\")\n",
    "\n",
    "if assigned[1]:\n",
    "    print(f\"ADC   (0001): {assigned[1]}\")\n",
    "else:\n",
    "    print(\"⚠️ ADC missing (modality 1)\")\n",
    "\n",
    "if assigned[2]:\n",
    "    print(f\"FLAIR (0002): {assigned[2]}\")\n",
    "else:\n",
    "    print(\"⚠️ FLAIR missing (modality 2)\")\n",
    "\n",
    "print(\"\\n📁 Ready for nnU-Net input:\", OUTPUT)\n",
    "print(\"🎉 Auto-preparation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT:\n",
      " \n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 1 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting ISLES22_0121:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ISLES22_0121\n",
      "\n",
      "\n",
      "STDERR:\n",
      " \n",
      "  0%|          | 0/73 [00:00<?, ?it/s]\n",
      "  1%|▏         | 1/73 [00:00<00:34,  2.09it/s]\n",
      "  5%|▌         | 4/73 [00:00<00:08,  8.32it/s]\n",
      " 10%|▉         | 7/73 [00:00<00:04, 13.38it/s]\n",
      " 14%|█▎        | 10/73 [00:00<00:03, 16.49it/s]\n",
      " 18%|█▊        | 13/73 [00:00<00:03, 19.78it/s]\n",
      " 23%|██▎       | 17/73 [00:01<00:02, 23.42it/s]\n",
      " 27%|██▋       | 20/73 [00:01<00:02, 25.02it/s]\n",
      " 33%|███▎      | 24/73 [00:01<00:01, 27.06it/s]\n",
      " 38%|███▊      | 28/73 [00:01<00:01, 27.99it/s]\n",
      " 44%|████▍     | 32/73 [00:01<00:01, 28.62it/s]\n",
      " 48%|████▊     | 35/73 [00:01<00:01, 28.46it/s]\n",
      " 53%|█████▎    | 39/73 [00:01<00:01, 29.88it/s]\n",
      " 59%|█████▉    | 43/73 [00:01<00:00, 30.37it/s]\n",
      " 64%|██████▍   | 47/73 [00:02<00:00, 31.54it/s]\n",
      " 70%|██████▉   | 51/73 [00:02<00:00, 32.41it/s]\n",
      " 75%|███████▌  | 55/73 [00:02<00:00, 32.84it/s]\n",
      " 81%|████████  | 59/73 [00:02<00:00, 33.29it/s]\n",
      " 86%|████████▋ | 63/73 [00:02<00:00, 33.88it/s]\n",
      " 92%|█████████▏| 67/73 [00:02<00:00, 34.11it/s]\n",
      " 97%|█████████▋| 71/73 [00:02<00:00, 34.46it/s]\n",
      "100%|██████████| 73/73 [00:02<00:00, 26.35it/s]\n",
      "\n",
      "\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"nnUNetv2_predict\",\n",
    "    \"-i\", \"D:/Capstone/Experiment 3/TEST_READY\",\n",
    "    \"-o\", \"D:/Capstone/Experiment 3/TEST_OUTPUT\",\n",
    "    \"-d\", \"123\",\n",
    "    \"-c\", \"2d\",\n",
    "    \"-tr\", \"nnUNetTrainer\",\n",
    "    \"-f\", \"0\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "print(\"STDOUT:\\n\", result.stdout)\n",
    "print(\"\\nSTDERR:\\n\", result.stderr)\n",
    "print(\"\\nReturn code:\", result.returncode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE — Overlays saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "PREPROC_FOLDER = r\"D:/Capstone/Experiment 3/nnUNet_preprocessed/Dataset123_ISLES22/nnUNetPlans_2d\"\n",
    "MASK_FOLDER = r\"D:/Capstone/Experiment 3/TEST_OUTPUT\"\n",
    "SAVE_FOLDER  = r\"D:/Capstone/Experiment 3/PNG_RESULTS\"\n",
    "case = \"ISLES22_0121\"\n",
    "\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Load (C, S, H, W)\n",
    "img = np.load(os.path.join(PREPROC_FOLDER, case + \".npy\"))\n",
    "\n",
    "# Choose ADC modality\n",
    "img_vis = img[1]\n",
    "\n",
    "# Load mask, convert to (S,H,W)\n",
    "mask = nib.load(os.path.join(MASK_FOLDER, case + \".nii.gz\")).get_fdata()\n",
    "mask_ax = np.transpose(mask, (2,0,1))\n",
    "\n",
    "# Custom pure red colormap\n",
    "red_cmap = ListedColormap([[0,0,0,0], [1,0,0,0.7]])  \n",
    "# index 0 = transparent, index 1 = red with alpha 0.7\n",
    "\n",
    "for i in range(img_vis.shape[0]):\n",
    "    if np.sum(mask_ax[i]) == 0:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img_vis[i], cmap='gray')\n",
    "    plt.imshow(mask_ax[i], cmap=red_cmap, alpha=0.7)\n",
    "    plt.title(f\"{case} — Slice {i} (ADC)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    out_path = os.path.join(SAVE_FOLDER, f\"{case}_overlay_slice_{i}.png\")\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(\"DONE — Overlays saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stroke found on slice: 20\n",
      "Stroke found on slice: 21\n",
      "Stroke found on slice: 22\n",
      "Stroke found on slice: 23\n",
      "Stroke found on slice: 24\n",
      "Stroke found on slice: 25\n",
      "Stroke found on slice: 26\n",
      "Stroke found on slice: 27\n",
      "Stroke found on slice: 28\n",
      "Stroke found on slice: 29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = np.transpose(mask, (2, 0, 1))   # S, H, W\n",
    "\n",
    "for i in range(mask.shape[0]):\n",
    "    if np.any(mask[i] == 1):\n",
    "        print(\"Stroke found on slice:\", i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
